{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf6VCdFGDe0K"
      },
      "source": [
        "Neural ODEs (based on https://arxiv.org/pdf/1806.07366.pdf):\n",
        "\n",
        "---\n",
        "\n",
        "Consider the following equations\n",
        "$$\\frac{dy}{dt} = f(t,y),~~ y(t_0) = y_0.$$\n",
        "One can write the solution to this ODE using $n$ discretized time steps via Euler's method,\n",
        "$$y_{n+1} = y_n + f(t_n, y_n)\\cdot(t_{n+1} - t_n). $$\n",
        "\n",
        ">**Enter Residual Networks, or Recurrent Neural Network Decoders!**\n",
        "\n",
        "The way these models work, input $h_{t+1}$ of $(t+1)^{\\text{th}}$ layer  is the sum of the post-activation $f(h_t, \\theta_t)$ of $t^{\\text{th}}$ layer and inputs $h_t$ to $t^{\\text{th}}$ layer. Here, $t \\in \\{0,\\cdots , T \\}$, with $h_0$ and $h_T$ respectively the input and output of the model, and $\\theta_t$ are the parameters. Let's compare\n",
        "$$h_{t+1} = h_t + f(h_t, \\theta_t)$$\n",
        "to the previous ODE. This network is analogous to a blacbox ODE solver, with $h_{0}$ and $h_{T}$ respectively equivalent to $y_{t_0}$ and $y_{t_T}$.\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        ">*Let's stare at the transformations across layers of a Resnet and vector fields from some ODE solver, for a few seconds.*\n",
        "![picture](https://drive.google.com/uc?export=view&id=1PPYirzPNZwg4TkRi2EVyVI8lHTsfyVrR)\n",
        "If one adds many hidden layers in the Resnet and takes smaller steps, it will very nicely approximate the ODE solver on the right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1PoFEfjcpHm"
      },
      "source": [
        "---\n",
        "\n",
        "**Example 0: Let's design a simple Residual Network to train on a toy dataset.** (Dataset courtesy, this blog - http://implicit-layers-tutorial.org/neural_odes/)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mL9c10Gd7JG"
      },
      "source": [
        "* Import packages (Let's use jax; and for differentiations, we will specify \"@jit\".)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t3vrVctMetz"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "import numpy.random as nprand\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4mzTSdGDdsv"
      },
      "source": [
        "* Start with a fully connected network (multi layer perceptron)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EapLbfEWfEG0"
      },
      "outputs": [],
      "source": [
        "def fcn(theta, xs):\n",
        "    for w, b in theta:\n",
        "      outputs = jnp.dot(xs, w) + b  # Linear transform\n",
        "      xs = jnp.tanh(outputs)        # Nonlinearity\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akXVee63fjpm"
      },
      "source": [
        "* Next, use the fully connected network to design a residual network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk6aoM5jfjJD"
      },
      "outputs": [],
      "source": [
        "def ResNet(theta, xs, L):\n",
        "    for i in range(L):\n",
        "      outputs = fcn(theta, xs) + xs\n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffoIG0a5jK1X"
      },
      "source": [
        "* Here's a toy dataset, 1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfmBQ7REjOb_",
        "outputId": "6aa29216-23cd-491f-dad9-1b85cdd0a4fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "input = jnp.reshape(jnp.linspace(-2.5, 2.5, 15), (15, 1))\n",
        "target = input**3 + 0.1 * input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjTlXj3qjrMQ"
      },
      "source": [
        "* Define forward KL divergence loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_wIKuzNkeya"
      },
      "outputs": [],
      "source": [
        "def L2_loss(theta, xs, ys):\n",
        "    f_x = ResNet(theta, xs, L)\n",
        "    return jnp.mean(jnp.sum((f_x - ys)**2, axis=1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4qdq4lllofa"
      },
      "source": [
        "* Define an initializer for parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CevNj4ptl06R"
      },
      "outputs": [],
      "source": [
        "def init_random_params(scale, N, rng=nprand.RandomState(0)):\n",
        "    return [(scale * rng.randn(p, q), scale * rng.randn(q))\n",
        "            for p, q, in zip(N[:-1], N[1:])]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKzxgTQmqyz"
      },
      "source": [
        "* Define a simple gradient descent optimizer using @jit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmBp5sM1mu5_"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def ResNet_gd(theta, xs, ys):\n",
        "    gradients = grad(L2_loss)(theta, xs, ys)\n",
        "    return [(w - step_size * dw, b - step_size * db)\n",
        "            for (w, b), (dw, db) in zip(theta, gradients)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhfhx1e5muZz"
      },
      "source": [
        "* Define hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcmUO0o0sPsp"
      },
      "outputs": [],
      "source": [
        "L = 4\n",
        "N = [1, 10, 100, 1]\n",
        "param_scale = 1.0\n",
        "step_size = 0.0005\n",
        "train_iters = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZVx9Kqjulwg"
      },
      "source": [
        "* Initialize the Network, train it, and plot the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "C1ZWANMNusz8",
        "outputId": "761c9fed-ad94-4c93-c769-0d312df23cc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'output')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# initialize parameters first\n",
        "ResNet_theta = init_random_params(param_scale, N)\n",
        "# update parameters using gradient descent, loss function\n",
        "for i in range(train_iters):\n",
        "    ResNet_theta = ResNet_gd(ResNet_theta, input, target)\n",
        "# plot results after training\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(6, 4), dpi=150)\n",
        "ax = fig.gca()\n",
        "ax.scatter(input, target, lw=0.5, color='red')\n",
        "fine_inputs = jnp.reshape(jnp.linspace(-3.0, 3.0, 300), (300, 1))\n",
        "ax.plot(fine_inputs, ResNet(ResNet_theta, fine_inputs, L), lw=0.5, color='blue')\n",
        "ax.set_xlabel('input')\n",
        "ax.set_ylabel('output')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzXi-KVqXIl1"
      },
      "source": [
        "---\n",
        "\n",
        "**Problem 0: Let's design a toy Neural ODE that can approximate the same data series well enough.**  \n",
        "\n",
        "---\n",
        "Hint: An ODE solver is defined as\n",
        "$$y(t_{n+1}) = y_{t_n} + \\int^{t_{n+1}}_{t_n} f(y_{t_n} , t_n , \\theta_{t_n}).$$\n",
        "To design a Neural ODE, one needs to design an optimizer for a scalar valued loss function $L()$, such that\n",
        "$$L(\\,y(t_{n+1})\\,) = L \\Big( \\, y_{t_n} + \\int^{t_{n+1}}_{t_n} f(y_{t_n} , t_n , \\theta_{t_n}) \\, \\Big) = L(\\, \\text{ODESolve}(y(t_n), f, t_n , t_{n+1}, \\theta_{t_n}) \\, ) .$$\n",
        "\n",
        ">In this case, we can use \"vmap\" function for batching.\n",
        "```\n",
        "from jax import vmap\n",
        "batched_neural_ode = vmap(insert_your_Neural_ODE_function_name, in_axes=(None, 0))\n",
        "```\n",
        "\n",
        "Let's begin!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfUUJbCMbdh8"
      },
      "source": [
        "----\n",
        "\n",
        "**Solution to Problem 0**\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnVwYAzpcMry"
      },
      "source": [
        "* Let us first concatenate the arguments of $f()$ as a tuple. Next, we can use the same fully connected network module \"fcn\", for function $f$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbjkB-P3cbw0"
      },
      "outputs": [],
      "source": [
        "def f_integrand(y_n, t_n, theta_t_n):\n",
        "    f_arguments = jnp.hstack([y_n, jnp.array(t_n)])\n",
        "    return fcn(theta_t_n, f_arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwBnxisddJsg"
      },
      "source": [
        "* We choose an ODE solver \"odeint\" from Jax, next. Please feel free to choose any other ODE solver that you like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbDb5Sd9dbvG"
      },
      "outputs": [],
      "source": [
        "from jax.experimental.ode import odeint\n",
        "\n",
        "def NODE(theta_t_n, y_n):\n",
        "    t0_tT = jnp.array([0.0, 1.0]) # define a tuple of start and end times.\n",
        "    y0, yT = odeint(f_integrand, y_n, t0_tT, theta_t_n)\n",
        "    return yT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxIQyeSAeGuz"
      },
      "source": [
        "* Define the loss function next, using \"vmap\" for batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVNC24A4eGQK"
      },
      "outputs": [],
      "source": [
        "from jax import vmap\n",
        "batched_NODE = vmap(NODE, in_axes=(None, 0))\n",
        "\n",
        "def NODE_L2loss(theta, xs, ys):\n",
        "    f_x = batched_NODE(theta, xs)\n",
        "    return jnp.mean(jnp.sum((f_x - ys)**2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMMTUI2Le8EO"
      },
      "source": [
        "* Define a simple gradient descent optimizer, as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_Wup8cjfA5l"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def NODE_gd(theta, xs, ys):\n",
        "    gradients = grad(NODE_L2loss)(theta, xs, ys)\n",
        "    return [(w - step_size * dw, b - step_size * db)\n",
        "            for (w, b), (dw, db) in zip(theta, gradients)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSzcNCNAgbx6"
      },
      "source": [
        "* Initialize and train this Neural ODE on the previous dataset, and plot to compare against the ResNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "ck_s28tKgjdd",
        "outputId": "f7315956-8669-47af-b76d-771c368434f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d4420a80dc0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define hyperparameters\n",
        "NODE_width = [2, 20, 1] # layer sizes\n",
        "# Initialize parameters.\n",
        "NODE_theta = init_random_params(param_scale, NODE_width)\n",
        "# Train the initialized network\n",
        "for i in range(train_iters):\n",
        "    NODE_theta = NODE_gd(NODE_theta, input, target)\n",
        "\n",
        "# Plot this toy neural ODE against previous ResNet for comparison\n",
        "# Plot resulting model.\n",
        "fig = plt.figure(figsize=(6, 4), dpi=150)\n",
        "ax = fig.gca()\n",
        "ax.scatter(input, target, lw=0.5, color='red')\n",
        "fine_inputs = jnp.reshape(jnp.linspace(-3.0, 3.0, 300), (300, 1))\n",
        "ax.plot(fine_inputs, ResNet(ResNet_theta, fine_inputs, L), lw=0.5, color='blue')\n",
        "ax.plot(fine_inputs, batched_NODE(NODE_theta, fine_inputs), lw=0.5, color='green')\n",
        "ax.set_xlabel('input')\n",
        "ax.set_ylabel('output')\n",
        "plt.legend(('Resnet', 'Neural ODE'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF9QM61bjcu6"
      },
      "source": [
        "***As we can see, this toy neural ODE can approximate some part of the data well, but mostly it's not the best model. Let us look at an actual harmonic oscillator dataset, and design a neural ODE for it as an exercise.***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj7u5qeRl9Jv"
      },
      "source": [
        "*Problem 1*: Let us consider the differential equation\n",
        "$$m \\, y''(t) + k\\, y(t) =0,$$\n",
        "for $m= 1.4$, $k=1.9$ in appropriate units.\n",
        "\n",
        "Boundary conditions are $$y(0)=1.2~,~ y(0.47)=0.09~,~y'(1)=0.$$\n",
        "\n",
        "The solution is $$y(t) = 0.043576 \\cos(1.16496 \\, t) + 0.101414 \\sin(1.16496 \\, t)   .$$\n",
        "\n",
        "> To solve this using Neural ODE, we first note that any arbitrary differential equation of order $n$, for any scalar function $y(t)$,\n",
        "$$G\\big(y(t), y'(t), y''(t), \\cdots , y^{(n)}(t),t \\big) = 0$$\n",
        "can be mapped into a system of first order differential equations\n",
        "$$y'_1(t) = y_2(t),\\\\\n",
        "y'_2(t) = y_3(t), \\\\\n",
        "\\vdots \\\\\n",
        "y'_n(t) = G^*\\big(y(t), y'(t), y''(t), \\cdots , y^{(n)}(t),t \\big).\n",
        "$$\n",
        "Here, $G^*$ is obtained by solving $G$ for $y^{(n)}(t)$.\n",
        "\n",
        "Now that this second order differential equation has been recast in terms of two different first order differential equations, our Neural ODE will need to converge to two different data series $\\{y'(t), y(t) \\}$ simultaneously.\n",
        "\n",
        "Let's stat building it up!\n",
        "\n",
        "---\n",
        "\n",
        "Hint (optional): Use Tensorflow Keras, MSE loss, Adam optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyHwmiSIq8-M"
      },
      "source": [
        "----\n",
        "\n",
        "**Solution to Problem 1**\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byu6LhAhsIKb"
      },
      "source": [
        "* Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfAdUfQwrueb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TjSPJgPsLUw"
      },
      "source": [
        "* Generate training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZebrJBNfrwaC"
      },
      "outputs": [],
      "source": [
        "# harmonic oscillator solution y(t)\n",
        "def y(t):\n",
        "    return 0.043576*np.cos(1.16496*t) + 0.101414*np.sin(1.16496*t)\n",
        "\n",
        "# first derivative of y(t)\n",
        "def y_prime(t):\n",
        "    return 0.118144*np.cos(1.16496*t) - 0.0507645*np.sin(1.16496*t)\n",
        "\n",
        "# generate random training points in the interval t=0...40\n",
        "x_train = np.random.rand(200)*30\n",
        "y_train = np.array([y(x_train), y_prime(x_train)]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9SXBxLVtJfY"
      },
      "source": [
        "* Create and compile a simple 2 hidden layer network with tanh activation and each layer size 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5lBVS8HtZoo"
      },
      "outputs": [],
      "source": [
        "ODE_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=tf.nn.tanh, input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(100, activation=tf.nn.tanh),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])\n",
        "ODE_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    loss=tf.keras.losses.MeanSquaredError()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o2YUgZcuSLF"
      },
      "source": [
        "Next, train this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XPabwd_uTrm",
        "outputId": "8ffa911b-5f22-4fb8-fb65-51fc29528603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 2846/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 2846: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 2847/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 2847: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 2848/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 2848: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 2849/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 2849: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0029\n",
            "Epoch 2850/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 2850: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 2851/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 2851: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 2852/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 2852: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 2853/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 2853: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "Epoch 2854/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 2854: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 2855/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 2855: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 2856/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 2856: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 2857/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 2857: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 2858/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 2858: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0031\n",
            "Epoch 2859/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 2859: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0043\n",
            "Epoch 2860/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0043\n",
            "Epoch 2860: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0044\n",
            "Epoch 2861/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 2861: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0034\n",
            "Epoch 2862/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 2862: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0035\n",
            "Epoch 2863/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 2863: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 2864/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 2864: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0032\n",
            "Epoch 2865/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 2865: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0032\n",
            "Epoch 2866/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 2866: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 2867/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 2867: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0030\n",
            "Epoch 2868/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 2868: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 2869/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 2869: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0024\n",
            "Epoch 2870/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 2870: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 2871/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 2871: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 2872/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 2872: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0026\n",
            "Epoch 2873/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 2873: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0029\n",
            "Epoch 2874/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 2874: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0032\n",
            "Epoch 2875/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 2875: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0050\n",
            "Epoch 2876/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0043\n",
            "Epoch 2876: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0046\n",
            "Epoch 2877/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0043\n",
            "Epoch 2877: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0045\n",
            "Epoch 2878/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0062\n",
            "Epoch 2878: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0051\n",
            "Epoch 2879/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 2879: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0041\n",
            "Epoch 2880/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 2880: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0042\n",
            "Epoch 2881/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 2881: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0041\n",
            "Epoch 2882/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 2882: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0037\n",
            "Epoch 2883/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0044\n",
            "Epoch 2883: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0040\n",
            "Epoch 2884/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 2884: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0036\n",
            "Epoch 2885/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 2885: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0032\n",
            "Epoch 2886/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046\n",
            "Epoch 2886: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0035\n",
            "Epoch 2887/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 2887: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0030\n",
            "Epoch 2888/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 2888: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0029\n",
            "Epoch 2889/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 2889: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 2890/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 2890: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0029\n",
            "Epoch 2891/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 2891: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "Epoch 2892/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 2892: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0032\n",
            "Epoch 2893/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 2893: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0034\n",
            "Epoch 2894/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 2894: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0038\n",
            "Epoch 2895/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 2895: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0034\n",
            "Epoch 2896/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 2896: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0038\n",
            "Epoch 2897/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 2897: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0033\n",
            "Epoch 2898/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0058\n",
            "Epoch 2898: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "Epoch 2899/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 2899: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0036\n",
            "Epoch 2900/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 2900: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 2901/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 2901: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 2902/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 2902: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0031\n",
            "Epoch 2903/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0059\n",
            "Epoch 2903: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0050\n",
            "Epoch 2904/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 2904: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0034\n",
            "Epoch 2905/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 2905: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0032\n",
            "Epoch 2906/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 2906: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0033\n",
            "Epoch 2907/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 2907: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0030\n",
            "Epoch 2908/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0044\n",
            "Epoch 2908: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0038\n",
            "Epoch 2909/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 2909: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0030\n",
            "Epoch 2910/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 2910: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 2911/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 2911: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0031\n",
            "Epoch 2912/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 2912: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "Epoch 2913/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 2913: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0047\n",
            "Epoch 2914/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 2914: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "Epoch 2915/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 2915: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0040\n",
            "Epoch 2916/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045\n",
            "Epoch 2916: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0036\n",
            "Epoch 2917/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 2917: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0037\n",
            "Epoch 2918/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045\n",
            "Epoch 2918: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0037\n",
            "Epoch 2919/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0051\n",
            "Epoch 2919: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0040\n",
            "Epoch 2920/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046\n",
            "Epoch 2920: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0037\n",
            "Epoch 2921/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0049\n",
            "Epoch 2921: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0036\n",
            "Epoch 2922/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0047\n",
            "Epoch 2922: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0032\n",
            "Epoch 2923/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 2923: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0033\n",
            "Epoch 2924/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 2924: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0034\n",
            "Epoch 2925/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 2925: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 2926/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 2926: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0025\n",
            "Epoch 2927/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 2927: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 2928/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 2928: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0028\n",
            "Epoch 2929/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 2929: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0029\n",
            "Epoch 2930/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 2930: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0025\n",
            "Epoch 2931/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 2931: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0029\n",
            "Epoch 2932/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 2932: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0027\n",
            "Epoch 2933/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 2933: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 2934/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 2934: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 2935/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0056\n",
            "Epoch 2935: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0045\n",
            "Epoch 2936/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 2936: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0035\n",
            "Epoch 2937/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 2937: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 2938/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 2938: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0033\n",
            "Epoch 2939/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 2939: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0039\n",
            "Epoch 2940/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 2940: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0037\n",
            "Epoch 2941/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046\n",
            "Epoch 2941: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0044\n",
            "Epoch 2942/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 2942: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0029\n",
            "Epoch 2943/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 2943: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 2944/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 2944: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0028\n",
            "Epoch 2945/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 2945: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0027\n",
            "Epoch 2946/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 2946: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 2947/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 2947: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0028\n",
            "Epoch 2948/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 2948: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0026\n",
            "Epoch 2949/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 2949: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 2950/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 2950: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0026\n",
            "Epoch 2951/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 2951: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 2952/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 2952: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0022\n",
            "Epoch 2953/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 2953: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 2954/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 2954: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0029\n",
            "Epoch 2955/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0047\n",
            "Epoch 2955: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0045\n",
            "Epoch 2956/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 2956: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 2957/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 2957: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 2958/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 2958: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 2959/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 2959: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0028\n",
            "Epoch 2960/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 2960: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0032\n",
            "Epoch 2961/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 2961: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0028\n",
            "Epoch 2962/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 2962: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 2963/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 2963: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 2964/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 2964: loss did not improve from 0.00213\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 2965/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 2999: loss improved from 0.00181 to 0.00173, saving model to weights\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0017\n",
            "Epoch 3000/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3000: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3001/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3001: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3002/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3002: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3003/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3003: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3004/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3004: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3005/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3005: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3006/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3006: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3007/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3007: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3008/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3008: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 3009/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3009: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3010/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3010: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 3011/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3011: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 3012/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3012: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0025\n",
            "Epoch 3013/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3013: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 3014/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3014: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3015/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3015: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 3016/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3016: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 3017/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3017: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 3018/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3018: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3019/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3019: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0026\n",
            "Epoch 3020/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3020: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0036\n",
            "Epoch 3021/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3021: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 3022/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3022: loss did not improve from 0.00173\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0022\n",
            "Epoch 3023/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3023: loss improved from 0.00173 to 0.00170, saving model to weights\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0017\n",
            "Epoch 3024/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3024: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 3025/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3025: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 3026/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3026: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3027/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3027: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3028/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3028: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3029/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3029: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3030/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3030: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 3031/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3031: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0034\n",
            "Epoch 3032/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3032: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0025\n",
            "Epoch 3033/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046\n",
            "Epoch 3033: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 3034/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3034: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0035\n",
            "Epoch 3035/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3035: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 3036/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3036: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 3037/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0062\n",
            "Epoch 3037: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0045\n",
            "Epoch 3038/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3038: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0047\n",
            "Epoch 3039/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3039: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 3040/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0052\n",
            "Epoch 3040: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0034\n",
            "Epoch 3041/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0056\n",
            "Epoch 3041: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0044\n",
            "Epoch 3042/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3042: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0050\n",
            "Epoch 3043/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3043: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0040\n",
            "Epoch 3044/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0058\n",
            "Epoch 3044: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0043\n",
            "Epoch 3045/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0063\n",
            "Epoch 3045: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0048\n",
            "Epoch 3046/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0052\n",
            "Epoch 3046: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0060\n",
            "Epoch 3047/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3047: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0039\n",
            "Epoch 3048/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3048: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0034\n",
            "Epoch 3049/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3049: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0034\n",
            "Epoch 3050/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0074\n",
            "Epoch 3050: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0051\n",
            "Epoch 3051/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0071\n",
            "Epoch 3051: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0069\n",
            "Epoch 3052/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3052: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0052\n",
            "Epoch 3053/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3053: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0041\n",
            "Epoch 3054/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0058\n",
            "Epoch 3054: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "Epoch 3055/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 3055: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0042\n",
            "Epoch 3056/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3056: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 3057/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3057: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3058/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3058: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 3059/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3059: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3060/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3060: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3061/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3061: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0023\n",
            "Epoch 3062/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3062: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0036\n",
            "Epoch 3063/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3063: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 3064/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3064: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 3065/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3065: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 3066/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3066: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3067/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3067: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 3068/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3068: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3069/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3069: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0022\n",
            "Epoch 3070/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3070: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3071/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3071: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3072/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3072: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 3073/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3073: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 3074/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3074: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 3075/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3075: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3076/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3076: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 3077/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3077: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0024\n",
            "Epoch 3078/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3078: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3079/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3079: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3080/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3080: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3081/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3081: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0019\n",
            "Epoch 3082/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3082: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0022\n",
            "Epoch 3083/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3083: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0022\n",
            "Epoch 3084/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3084: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3085/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3085: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 3086/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3086: loss improved from 0.00170 to 0.00170, saving model to weights\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0017\n",
            "Epoch 3087/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3087: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0019\n",
            "Epoch 3088/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3088: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3089/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3089: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3090/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3090: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 3091/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3091: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 3092/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3092: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0021\n",
            "Epoch 3093/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3093: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0022\n",
            "Epoch 3094/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3094: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0027\n",
            "Epoch 3095/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3095: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 3096/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3096: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0018\n",
            "Epoch 3097/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3097: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 3098/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3098: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 3099/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3099: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 3100/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3100: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0027\n",
            "Epoch 3101/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3101: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3102/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3102: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 3103/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3103: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 3104/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3104: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0021\n",
            "Epoch 3105/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3105: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3106/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3106: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0022\n",
            "Epoch 3107/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3107: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 3108/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3108: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3109/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3109: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0024\n",
            "Epoch 3110/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3110: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 3111/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3111: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3112/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3112: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 3113/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3113: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 3114/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3114: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 3115/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3115: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 3116/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3116: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3117/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3117: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 3118/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3118: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 3119/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3119: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3120/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3120: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 3121/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3121: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3122/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3122: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 3123/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3123: loss did not improve from 0.00170\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 3124/4500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0027\n",
            "Epoch 3152/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3152: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3153/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3153: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0025\n",
            "Epoch 3154/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3154: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 3155/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3155: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3156/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3156: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0033\n",
            "Epoch 3157/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3157: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0028\n",
            "Epoch 3158/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3158: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0025\n",
            "Epoch 3159/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3159: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0035\n",
            "Epoch 3160/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3160: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 3161/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3161: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0029\n",
            "Epoch 3162/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3162: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0027\n",
            "Epoch 3163/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0069\n",
            "Epoch 3163: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0050\n",
            "Epoch 3164/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3164: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0037\n",
            "Epoch 3165/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3165: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0029\n",
            "Epoch 3166/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3166: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 3167/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046\n",
            "Epoch 3167: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0033\n",
            "Epoch 3168/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0044\n",
            "Epoch 3168: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0032\n",
            "Epoch 3169/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3169: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0034\n",
            "Epoch 3170/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3170: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 3171/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3171: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0023\n",
            "Epoch 3172/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3172: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 3173/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3173: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 3174/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3174: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0022\n",
            "Epoch 3175/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3175: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0019\n",
            "Epoch 3176/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3176: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 3177/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3177: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0021\n",
            "Epoch 3178/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3178: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3179/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3179: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 3180/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3180: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3181/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3181: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 3182/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3182: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0031\n",
            "Epoch 3183/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3183: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0033\n",
            "Epoch 3184/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3184: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 3185/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3185: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0037\n",
            "Epoch 3186/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3186: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0023\n",
            "Epoch 3187/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3187: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0028\n",
            "Epoch 3188/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3188: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0028\n",
            "Epoch 3189/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3189: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0027\n",
            "Epoch 3190/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3190: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0025\n",
            "Epoch 3191/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3191: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0028\n",
            "Epoch 3192/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3192: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0026\n",
            "Epoch 3193/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3193: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3194/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3194: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0020\n",
            "Epoch 3195/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3195: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 3196/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3196: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3197/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3197: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3198/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3198: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0023\n",
            "Epoch 3199/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3199: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "Epoch 3200/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3200: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0033\n",
            "Epoch 3201/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3201: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0035\n",
            "Epoch 3202/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3202: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0034\n",
            "Epoch 3203/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3203: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3204/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3204: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 3205/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3205: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3206/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3206: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0028\n",
            "Epoch 3207/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3207: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0028\n",
            "Epoch 3208/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3208: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0024\n",
            "Epoch 3209/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3209: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0029\n",
            "Epoch 3210/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3210: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 3211/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3211: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 3212/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3212: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3213/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3213: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0018\n",
            "Epoch 3214/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3214: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0019\n",
            "Epoch 3215/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3215: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 3216/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3216: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0020\n",
            "Epoch 3217/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3217: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 3218/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3218: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0017\n",
            "Epoch 3219/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3219: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 3220/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3220: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0020\n",
            "Epoch 3221/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3221: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 3222/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3222: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0023\n",
            "Epoch 3223/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3223: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 3224/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3224: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 3225/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3225: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0023\n",
            "Epoch 3226/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3226: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3227/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3227: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3228/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3228: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3229/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3229: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3230/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3230: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3231/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3231: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3232/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3232: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3233/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3233: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 3234/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3234: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0022\n",
            "Epoch 3235/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3235: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 3236/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3236: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 3237/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3237: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0028\n",
            "Epoch 3238/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3238: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3239/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3239: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 3240/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3240: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0034\n",
            "Epoch 3241/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3241: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0030\n",
            "Epoch 3242/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3242: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3243/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0053\n",
            "Epoch 3243: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0036\n",
            "Epoch 3244/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3244: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0032\n",
            "Epoch 3245/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3245: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0029\n",
            "Epoch 3246/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3246: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0029\n",
            "Epoch 3247/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0047\n",
            "Epoch 3247: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0033\n",
            "Epoch 3248/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3248: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "Epoch 3249/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3249: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 3250/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3250: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3251/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3251: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0019\n",
            "Epoch 3252/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3252: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0020\n",
            "Epoch 3253/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3253: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3254/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3254: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0021\n",
            "Epoch 3255/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3255: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0033\n",
            "Epoch 3256/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3256: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0034\n",
            "Epoch 3257/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3257: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 3258/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3258: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 3259/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3259: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 3260/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3260: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 3261/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3261: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 3262/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3262: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3263/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3263: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 3264/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3264: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 3265/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3265: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0044\n",
            "Epoch 3266/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3266: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 3267/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3267: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 3268/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3268: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 3269/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3269: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 3270/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3270: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 3271/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3271: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 3272/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3272: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3273/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3273: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 3274/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3274: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0019\n",
            "Epoch 3275/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3275: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0022\n",
            "Epoch 3276/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3276: loss did not improve from 0.00158\n",
            "\n",
            "Epoch 3308: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0035\n",
            "Epoch 3309/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0053\n",
            "Epoch 3309: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0046\n",
            "Epoch 3310/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3310: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0036\n",
            "Epoch 3311/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3311: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3312/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3312: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 3313/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3313: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0023\n",
            "Epoch 3314/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3314: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3315/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3315: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 3316/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3316: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3317/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3317: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3318/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3318: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0022\n",
            "Epoch 3319/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3319: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3320/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3320: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3321/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3321: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3322/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3322: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 3323/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3323: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0024\n",
            "Epoch 3324/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3324: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3325/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3325: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3326/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3326: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3327/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3327: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0022\n",
            "Epoch 3328/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0044\n",
            "Epoch 3328: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0035\n",
            "Epoch 3329/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3329: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 3330/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3330: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 3331/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045\n",
            "Epoch 3331: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0036\n",
            "Epoch 3332/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3332: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0031\n",
            "Epoch 3333/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3333: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0039\n",
            "Epoch 3334/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3334: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3335/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3335: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0035\n",
            "Epoch 3336/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0055\n",
            "Epoch 3336: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0042\n",
            "Epoch 3337/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3337: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0042\n",
            "Epoch 3338/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3338: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0043\n",
            "Epoch 3339/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3339: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0033\n",
            "Epoch 3340/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3340: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 3341/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3341: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "Epoch 3342/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3342: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 3343/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3343: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0027\n",
            "Epoch 3344/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3344: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 3345/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3345: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 3346/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3346: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0034\n",
            "Epoch 3347/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3347: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 3348/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3348: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 3349/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3349: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0028\n",
            "Epoch 3350/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3350: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 3351/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3351: loss did not improve from 0.00158\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0023\n",
            "Epoch 3352/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3352: loss improved from 0.00158 to 0.00157, saving model to weights\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0016\n",
            "Epoch 3353/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3353: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3354/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3354: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0033\n",
            "Epoch 3355/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3355: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0023\n",
            "Epoch 3356/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3356: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0029\n",
            "Epoch 3357/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3357: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0046\n",
            "Epoch 3358/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3358: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 3359/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0075\n",
            "Epoch 3359: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0063\n",
            "Epoch 3360/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3360: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0039\n",
            "Epoch 3361/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3361: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0033\n",
            "Epoch 3362/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3362: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0036\n",
            "Epoch 3363/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3363: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3364/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0044\n",
            "Epoch 3364: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0037\n",
            "Epoch 3365/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3365: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "Epoch 3366/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3366: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 3367/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3367: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0050\n",
            "Epoch 3368/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3368: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0033\n",
            "Epoch 3369/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3369: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0034\n",
            "Epoch 3370/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0054\n",
            "Epoch 3370: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0046\n",
            "Epoch 3371/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3371: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0034\n",
            "Epoch 3372/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3372: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 3373/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0056\n",
            "Epoch 3373: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0050\n",
            "Epoch 3374/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3374: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 3375/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3375: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0036\n",
            "Epoch 3376/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3376: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "Epoch 3377/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3377: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 3378/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045\n",
            "Epoch 3378: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0038\n",
            "Epoch 3379/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3379: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3380/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3380: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3381/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3381: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 3382/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3382: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3383/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3383: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3384/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3384: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3385/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3385: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3386/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3386: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 3387/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3387: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0019\n",
            "Epoch 3388/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3388: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 3389/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3389: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3390/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3390: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0030\n",
            "Epoch 3391/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3391: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 3392/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3392: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 3393/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3393: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0025\n",
            "Epoch 3394/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3394: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0033\n",
            "Epoch 3395/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3395: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0028\n",
            "Epoch 3396/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3396: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 3397/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3397: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 3398/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3398: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0032\n",
            "Epoch 3399/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3399: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0025\n",
            "Epoch 3400/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3400: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 3401/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3401: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 3402/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3402: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 3403/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3403: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 3404/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3404: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 3405/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0065\n",
            "Epoch 3405: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0045\n",
            "Epoch 3406/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3406: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0040\n",
            "Epoch 3407/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3407: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 3408/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3408: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0026\n",
            "Epoch 3409/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3409: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 3410/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3410: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 3411/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3411: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3412/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3412: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 3413/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3413: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0032\n",
            "Epoch 3414/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3414: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 3415/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3415: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3416/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3416: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 3417/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3417: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3418/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3418: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0016\n",
            "Epoch 3419/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3419: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 3420/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3420: loss did not improve from 0.00157\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 3421/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3421: loss improved from 0.00157 to 0.00150, saving model to weights\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0015\n",
            "Epoch 3422/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3422: loss improved from 0.00150 to 0.00139, saving model to weights\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0014\n",
            "Epoch 3423/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3423: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3424/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3424: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 3425/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3425: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 3426/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3426: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 3427/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3427: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 3428/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3428: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 3429/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3429: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0016\n",
            "Epoch 3430/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3430: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 3431/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3431: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 3432/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3432: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3433/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3474: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 3475/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3475: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3476/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3476: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 3477/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3477: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0028\n",
            "Epoch 3478/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3478: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3479/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3479: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3480/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3480: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 3481/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3481: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3482/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3482: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3483/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3483: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3484/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3484: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3485/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3485: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 3486/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3486: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0030\n",
            "Epoch 3487/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3487: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 3488/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3488: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 3489/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3489: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 3490/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3490: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3491/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3491: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 3492/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3492: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 3493/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3493: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 3494/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3494: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 3495/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3495: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3496/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3496: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0027\n",
            "Epoch 3497/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3497: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3498/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3498: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0033\n",
            "Epoch 3499/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3499: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0026\n",
            "Epoch 3500/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3500: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 3501/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3501: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0027\n",
            "Epoch 3502/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3502: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 3503/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3503: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 3504/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3504: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 3505/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3505: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 3506/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3506: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 3507/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3507: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 3508/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3508: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 3509/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3509: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0023\n",
            "Epoch 3510/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3510: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0015\n",
            "Epoch 3511/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3511: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3512/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3512: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3513/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3513: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3514/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3514: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 3515/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3515: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 3516/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3516: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 3517/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3517: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0028\n",
            "Epoch 3518/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3518: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 3519/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3519: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 3520/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3520: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 3521/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3521: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0026\n",
            "Epoch 3522/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3522: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3523/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3523: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 3524/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3524: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0040\n",
            "Epoch 3525/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3525: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3526/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3526: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0028\n",
            "Epoch 3527/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3527: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3528/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3528: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0016\n",
            "Epoch 3529/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3529: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 3530/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3530: loss did not improve from 0.00139\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3531/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3531: loss improved from 0.00139 to 0.00136, saving model to weights\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0014\n",
            "Epoch 3532/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3532: loss did not improve from 0.00136\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3533/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3533: loss did not improve from 0.00136\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 3534/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3534: loss improved from 0.00136 to 0.00113, saving model to weights\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0011\n",
            "Epoch 3535/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3535: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 3536/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3536: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 3537/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4214e-04\n",
            "Epoch 3537: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 3538/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3538: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0015\n",
            "Epoch 3539/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3539: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 3540/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3540: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3541/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3541: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3542/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3542: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 3543/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3543: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 3544/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3544: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0034\n",
            "Epoch 3545/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0061\n",
            "Epoch 3545: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0037\n",
            "Epoch 3546/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3546: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 3547/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3547: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3548/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3548: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0024\n",
            "Epoch 3549/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3549: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 3550/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3550: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3551/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3551: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 3552/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3552: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 3553/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3553: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 3554/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3554: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3555/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3555: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3556/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3556: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3557/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3557: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0016\n",
            "Epoch 3558/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4674e-04\n",
            "Epoch 3558: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 3559/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3559: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3560/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3560: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 3561/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3561: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 3562/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3562: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3563/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3563: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 3564/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3564: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 3565/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3565: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 3566/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3566: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0016\n",
            "Epoch 3567/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3567: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 3568/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9342e-04\n",
            "Epoch 3568: loss improved from 0.00113 to 0.00112, saving model to weights\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0011\n",
            "Epoch 3569/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3569: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 3570/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3570: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3571/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3571: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0019\n",
            "Epoch 3572/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3572: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 3573/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3573: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 3574/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3574: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 3575/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3575: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 3576/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3576: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0016\n",
            "Epoch 3577/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3577: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 3578/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8022e-04\n",
            "Epoch 3578: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 3579/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3579: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 3580/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3580: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 3581/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.8891e-04\n",
            "Epoch 3581: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3582/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3582: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 3583/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3583: loss did not improve from 0.00112\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3584/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3584: loss improved from 0.00112 to 0.00100, saving model to weights\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0010\n",
            "Epoch 3585/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3585: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 3586/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3586: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3587/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3587: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3588/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3588: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 3589/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3589: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3590/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3590: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 3591/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3591: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 3592/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3592: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 3593/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3593: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 3594/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0250e-04\n",
            "Epoch 3594: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3595/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3595: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 3596/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3596: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3597/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3597: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0020\n",
            "Epoch 3598/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.3671e-04\n",
            "Epoch 3598: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0020\n",
            "Epoch 3599/4500\n",
            "Epoch 3637/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3637: loss did not improve from 0.00100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 3638/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.3008e-04\n",
            "Epoch 3638: loss improved from 0.00100 to 0.00083, saving model to weights\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 8.3170e-04\n",
            "Epoch 3639/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2961e-04\n",
            "Epoch 3639: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3145e-04\n",
            "Epoch 3640/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3640: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3641/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3641: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 3642/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3642: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 3643/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3643: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 3644/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3644: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 3645/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3645: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3646/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3646: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 3647/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3647: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 3648/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3648: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3649/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3649: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 3650/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3650: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 3651/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3651: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0033\n",
            "Epoch 3652/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3652: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3653/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3653: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3654/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3654: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0028\n",
            "Epoch 3655/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3655: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0017\n",
            "Epoch 3656/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3656: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3657/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3657: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0027\n",
            "Epoch 3658/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3658: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 3659/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4828e-04\n",
            "Epoch 3659: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 3660/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3660: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 3661/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3661: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3662/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3662: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 3663/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3663: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 3664/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9917e-04\n",
            "Epoch 3664: loss did not improve from 0.00083\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9289e-04\n",
            "Epoch 3665/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7510e-04\n",
            "Epoch 3665: loss improved from 0.00083 to 0.00072, saving model to weights\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 7.2441e-04\n",
            "Epoch 3666/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7213e-04\n",
            "Epoch 3666: loss did not improve from 0.00072\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5565e-04\n",
            "Epoch 3667/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4594e-04\n",
            "Epoch 3667: loss improved from 0.00072 to 0.00072, saving model to weights\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 7.1573e-04\n",
            "Epoch 3668/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3530e-04\n",
            "Epoch 3668: loss improved from 0.00072 to 0.00065, saving model to weights\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 6.4604e-04\n",
            "Epoch 3669/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8778e-04\n",
            "Epoch 3669: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6177e-04\n",
            "Epoch 3670/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8599e-04\n",
            "Epoch 3670: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.8539e-04\n",
            "Epoch 3671/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6080e-04\n",
            "Epoch 3671: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3291e-04\n",
            "Epoch 3672/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.3243e-04\n",
            "Epoch 3672: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5926e-04\n",
            "Epoch 3673/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7659e-04\n",
            "Epoch 3673: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9196e-04\n",
            "Epoch 3674/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9967e-04\n",
            "Epoch 3674: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2837e-04\n",
            "Epoch 3675/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9256e-04\n",
            "Epoch 3675: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5856e-04\n",
            "Epoch 3676/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3676: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0014\n",
            "Epoch 3677/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3677: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 3678/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3678: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 3679/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3679: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 3680/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3680: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3681/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3681: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3682/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3682: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7886e-04\n",
            "Epoch 3683/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6584e-04\n",
            "Epoch 3683: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6813e-04\n",
            "Epoch 3684/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3766e-04\n",
            "Epoch 3684: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4852e-04\n",
            "Epoch 3685/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6637e-04\n",
            "Epoch 3685: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.6827e-04\n",
            "Epoch 3686/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3686: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3145e-04\n",
            "Epoch 3687/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3640e-04\n",
            "Epoch 3687: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0010\n",
            "Epoch 3688/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3688: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4570e-04\n",
            "Epoch 3689/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3689: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0016\n",
            "Epoch 3690/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0146e-04\n",
            "Epoch 3690: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 3691/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3691: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0032\n",
            "Epoch 3692/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3692: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 3693/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7914e-04\n",
            "Epoch 3693: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0014\n",
            "Epoch 3694/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3694: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 3695/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3695: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 3696/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3696: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 3697/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3697: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 3698/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3698: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 3699/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3699: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3700/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3700: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0017\n",
            "Epoch 3701/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3701: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0030\n",
            "Epoch 3702/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3702: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 3703/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3703: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 3704/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0043\n",
            "Epoch 3704: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0036\n",
            "Epoch 3705/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3705: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0037\n",
            "Epoch 3706/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3706: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0044\n",
            "Epoch 3707/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3707: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "Epoch 3708/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0061\n",
            "Epoch 3708: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0037\n",
            "Epoch 3709/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0048\n",
            "Epoch 3709: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0038\n",
            "Epoch 3710/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3710: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0031\n",
            "Epoch 3711/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3711: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0029\n",
            "Epoch 3712/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3712: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0025\n",
            "Epoch 3713/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3713: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0024\n",
            "Epoch 3714/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3714: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 3715/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3715: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 3716/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3716: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3717/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3717: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3718/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3718: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 3719/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3719: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3720/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3720: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0013\n",
            "Epoch 3721/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3721: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 3722/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3722: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0012\n",
            "Epoch 3723/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3723: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 3724/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3724: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0018\n",
            "Epoch 3725/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3725: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 3726/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3726: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0014\n",
            "Epoch 3727/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3727: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3728/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.4639e-04\n",
            "Epoch 3728: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.6197e-04\n",
            "Epoch 3729/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.6963e-04\n",
            "Epoch 3729: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6869e-04\n",
            "Epoch 3730/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0588e-04\n",
            "Epoch 3730: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5168e-04\n",
            "Epoch 3731/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7468e-04\n",
            "Epoch 3731: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.9698e-04\n",
            "Epoch 3732/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1020e-04\n",
            "Epoch 3732: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0003e-04\n",
            "Epoch 3733/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6363e-04\n",
            "Epoch 3733: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9545e-04\n",
            "Epoch 3734/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.7618e-04\n",
            "Epoch 3734: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.1948e-04\n",
            "Epoch 3735/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1389e-04\n",
            "Epoch 3735: loss did not improve from 0.00065\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0173e-04\n",
            "Epoch 3736/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8101e-04\n",
            "Epoch 3736: loss improved from 0.00065 to 0.00063, saving model to weights\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 6.2824e-04\n",
            "Epoch 3737/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3422e-04\n",
            "Epoch 3737: loss improved from 0.00063 to 0.00061, saving model to weights\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 6.1219e-04\n",
            "Epoch 3738/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9755e-04\n",
            "Epoch 3738: loss did not improve from 0.00061\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5074e-04\n",
            "Epoch 3739/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9203e-04\n",
            "Epoch 3739: loss improved from 0.00061 to 0.00056, saving model to weights\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.6112e-04\n",
            "Epoch 3740/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7649e-04\n",
            "Epoch 3740: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8557e-04\n",
            "Epoch 3741/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0881e-04\n",
            "Epoch 3741: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5573e-04\n",
            "Epoch 3742/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.3819e-04\n",
            "Epoch 3742: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7464e-04\n",
            "Epoch 3743/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2275e-04\n",
            "Epoch 3743: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4594e-04\n",
            "Epoch 3744/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0041e-04\n",
            "Epoch 3744: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2208e-04\n",
            "Epoch 3745/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6824e-04\n",
            "Epoch 3745: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8243e-04\n",
            "Epoch 3746/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5033e-04\n",
            "Epoch 3746: loss improved from 0.00056 to 0.00051, saving model to weights\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.1019e-04\n",
            "Epoch 3747/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8338e-04\n",
            "Epoch 3747: loss improved from 0.00051 to 0.00051, saving model to weights\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.0524e-04\n",
            "Epoch 3748/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3250e-04\n",
            "Epoch 3748: loss improved from 0.00051 to 0.00046, saving model to weights\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.6139e-04\n",
            "Epoch 3749/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8970e-04\n",
            "Epoch 3749: loss did not improve from 0.00046\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.9247e-04\n",
            "Epoch 3750/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4422e-04\n",
            "Epoch 3750: loss improved from 0.00046 to 0.00041, saving model to weights\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.1146e-04\n",
            "Epoch 3751/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2280e-04\n",
            "Epoch 3751: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7203e-04\n",
            "Epoch 3752/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9306e-04\n",
            "Epoch 3752: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8005e-04\n",
            "Epoch 3753/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.5834e-04\n",
            "Epoch 3753: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3153e-04\n",
            "Epoch 3754/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3415e-04\n",
            "Epoch 3754: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6057e-04\n",
            "Epoch 3755/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0922e-04\n",
            "Epoch 3755: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2473e-04\n",
            "Epoch 3756/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1800e-04\n",
            "Epoch 3756: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1942e-04\n",
            "Epoch 3757/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9215e-04\n",
            "Epoch 3757: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.8951e-04\n",
            "Epoch 3758/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9151e-04\n",
            "Epoch 3758: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4397e-04\n",
            "Epoch 3759/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.9743e-04\n",
            "Epoch 3759: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0212e-04\n",
            "Epoch 3760/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1573e-04\n",
            "Epoch 3760: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1356e-04\n",
            "Epoch 3761/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3761: loss did not improve from 0.00041\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5290e-04\n",
            "2/2 [==============================] - ETA: 0s - loss: 6.7911e-04\n",
            "Epoch 3895: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 6.7911e-04\n",
            "Epoch 3896/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8815e-04\n",
            "Epoch 3896: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.0194e-04\n",
            "Epoch 3897/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5305e-04\n",
            "Epoch 3897: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.8371e-04\n",
            "Epoch 3898/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9652e-04\n",
            "Epoch 3898: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.0098e-04\n",
            "Epoch 3899/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1718e-04\n",
            "Epoch 3899: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.2438e-04\n",
            "Epoch 3900/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4663e-04\n",
            "Epoch 3900: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.9294e-04\n",
            "Epoch 3901/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1429e-04\n",
            "Epoch 3901: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0458e-04\n",
            "Epoch 3902/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1735e-04\n",
            "Epoch 3902: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.4517e-04\n",
            "Epoch 3903/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0988e-04\n",
            "Epoch 3903: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.5724e-04\n",
            "Epoch 3904/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2868e-04\n",
            "Epoch 3904: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 4.8576e-04\n",
            "Epoch 3905/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8258e-04\n",
            "Epoch 3905: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.4501e-04\n",
            "Epoch 3906/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3906: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4877e-04\n",
            "Epoch 3907/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1815e-04\n",
            "Epoch 3907: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9318e-04\n",
            "Epoch 3908/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5730e-04\n",
            "Epoch 3908: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8213e-04\n",
            "Epoch 3909/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7359e-04\n",
            "Epoch 3909: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 4.6973e-04\n",
            "Epoch 3910/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8212e-04\n",
            "Epoch 3910: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.7357e-04\n",
            "Epoch 3911/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3470e-04\n",
            "Epoch 3911: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4969e-04\n",
            "Epoch 3912/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8082e-04\n",
            "Epoch 3912: loss improved from 0.00033 to 0.00032, saving model to weights\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.1610e-04\n",
            "Epoch 3913/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1801e-04\n",
            "Epoch 3913: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.4492e-04\n",
            "Epoch 3914/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3534e-04\n",
            "Epoch 3914: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.2142e-04\n",
            "Epoch 3915/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6103e-04\n",
            "Epoch 3915: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8321e-04\n",
            "Epoch 3916/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4394e-04\n",
            "Epoch 3916: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.9897e-04\n",
            "Epoch 3917/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2780e-04\n",
            "Epoch 3917: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2151e-04\n",
            "Epoch 3918/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9503e-04\n",
            "Epoch 3918: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 3919/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3919: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7191e-04\n",
            "Epoch 3920/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3920: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3921/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3921: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0769e-04\n",
            "Epoch 3922/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3922: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 3923/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9322e-04\n",
            "Epoch 3923: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9806e-04\n",
            "Epoch 3924/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3924: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.7440e-04\n",
            "Epoch 3925/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3670e-04\n",
            "Epoch 3925: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4619e-04\n",
            "Epoch 3926/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3926: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2662e-04\n",
            "Epoch 3927/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3927: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3928/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3928: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0454e-04\n",
            "Epoch 3929/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3929: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3930/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3930: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5450e-04\n",
            "Epoch 3931/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5300e-04\n",
            "Epoch 3931: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3279e-04\n",
            "Epoch 3932/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1425e-04\n",
            "Epoch 3932: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.3313e-04\n",
            "Epoch 3933/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0683e-04\n",
            "Epoch 3933: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3311e-04\n",
            "Epoch 3934/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3553e-04\n",
            "Epoch 3934: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7302e-04\n",
            "Epoch 3935/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3935: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 3936/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9545e-04\n",
            "Epoch 3936: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.7310e-04\n",
            "Epoch 3937/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0659e-04\n",
            "Epoch 3937: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.6630e-04\n",
            "Epoch 3938/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2926e-04\n",
            "Epoch 3938: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5233e-04\n",
            "Epoch 3939/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3939: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8238e-04\n",
            "Epoch 3940/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4331e-04\n",
            "Epoch 3940: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2140e-04\n",
            "Epoch 3941/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3343e-04\n",
            "Epoch 3941: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7186e-04\n",
            "Epoch 3942/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0956e-04\n",
            "Epoch 3942: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.4963e-04\n",
            "Epoch 3943/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7741e-04\n",
            "Epoch 3943: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.5869e-04\n",
            "Epoch 3944/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8411e-04\n",
            "Epoch 3944: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.1124e-04\n",
            "Epoch 3945/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2521e-04\n",
            "Epoch 3945: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.8596e-04\n",
            "Epoch 3946/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7181e-04\n",
            "Epoch 3946: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2095e-04\n",
            "Epoch 3947/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8618e-04\n",
            "Epoch 3947: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.5303e-04\n",
            "Epoch 3948/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3948: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 3949/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7294e-04\n",
            "Epoch 3949: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1089e-04\n",
            "Epoch 3950/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3950: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3951/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3604e-04\n",
            "Epoch 3951: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1556e-04\n",
            "Epoch 3952/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.4679e-04\n",
            "Epoch 3952: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.3799e-04\n",
            "Epoch 3953/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1090e-04\n",
            "Epoch 3953: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8362e-04\n",
            "Epoch 3954/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1002e-04\n",
            "Epoch 3954: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.1242e-04\n",
            "Epoch 3955/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4935e-04\n",
            "Epoch 3955: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6866e-04\n",
            "Epoch 3956/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0476e-04\n",
            "Epoch 3956: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.2312e-04\n",
            "Epoch 3957/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7303e-04\n",
            "Epoch 3957: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.8040e-04\n",
            "Epoch 3958/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0264e-04\n",
            "Epoch 3958: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.3924e-04\n",
            "Epoch 3959/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8742e-04\n",
            "Epoch 3959: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6064e-04\n",
            "Epoch 3960/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5956e-04\n",
            "Epoch 3960: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.6001e-04\n",
            "Epoch 3961/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.8460e-04\n",
            "Epoch 3961: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2044e-04\n",
            "Epoch 3962/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5824e-04\n",
            "Epoch 3962: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8605e-04\n",
            "Epoch 3963/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8761e-04\n",
            "Epoch 3963: loss did not improve from 0.00032\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8142e-04\n",
            "Epoch 3964/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5344e-04\n",
            "Epoch 3964: loss improved from 0.00032 to 0.00030, saving model to weights\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.0094e-04\n",
            "Epoch 3965/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9286e-04\n",
            "Epoch 3965: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.0666e-04\n",
            "Epoch 3966/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.1198e-04\n",
            "Epoch 3966: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.5558e-04\n",
            "Epoch 3967/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7691e-04\n",
            "Epoch 3967: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1549e-04\n",
            "Epoch 3968/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7791e-04\n",
            "Epoch 3968: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4461e-04\n",
            "Epoch 3969/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2579e-04\n",
            "Epoch 3969: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2579e-04\n",
            "Epoch 3970/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3970: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 3971/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8002e-04\n",
            "Epoch 3971: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.7462e-04\n",
            "Epoch 3972/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3972: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3973/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9889e-04\n",
            "Epoch 3973: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3974/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3974: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0011\n",
            "Epoch 3975/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1239e-04\n",
            "Epoch 3975: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9760e-04\n",
            "Epoch 3976/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9545e-04\n",
            "Epoch 3976: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3316e-04\n",
            "Epoch 3977/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7779e-04\n",
            "Epoch 3977: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5981e-04\n",
            "Epoch 3978/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3978: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4838e-04\n",
            "Epoch 3979/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.6583e-04\n",
            "Epoch 3979: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0200e-04\n",
            "Epoch 3980/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2995e-04\n",
            "Epoch 3980: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.7398e-04\n",
            "Epoch 3981/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7868e-04\n",
            "Epoch 3981: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7485e-04\n",
            "Epoch 3982/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.0221e-04\n",
            "Epoch 3982: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.0011e-04\n",
            "Epoch 3983/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4353e-04\n",
            "Epoch 3983: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.1864e-04\n",
            "Epoch 3984/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8807e-04\n",
            "Epoch 3984: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8063e-04\n",
            "Epoch 3985/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4944e-04\n",
            "Epoch 3985: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6162e-04\n",
            "Epoch 3986/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9457e-04\n",
            "Epoch 3986: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.6308e-04\n",
            "Epoch 3987/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4499e-04\n",
            "Epoch 3987: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.8812e-04\n",
            "Epoch 3988/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5478e-04\n",
            "Epoch 3988: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.2432e-04\n",
            "Epoch 3989/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3824e-04\n",
            "Epoch 3989: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.9548e-04\n",
            "Epoch 3990/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2404e-04\n",
            "Epoch 3990: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1569e-04\n",
            "Epoch 3991/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3991: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7819e-04\n",
            "Epoch 3992/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1603e-04\n",
            "Epoch 3992: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2973e-04\n",
            "Epoch 3993/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3993: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 3994/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0838e-04\n",
            "Epoch 3994: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5850e-04\n",
            "Epoch 3995/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.1001e-04\n",
            "Epoch 3995: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3311e-04\n",
            "Epoch 3996/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3657e-04\n",
            "Epoch 3996: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8041e-04\n",
            "Epoch 3997/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5112e-04\n",
            "Epoch 3997: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0013e-04\n",
            "Epoch 3998/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9995e-04\n",
            "Epoch 3998: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 3999/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1604e-04\n",
            "Epoch 3999: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6765e-04\n",
            "Epoch 4000/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4000: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 4001/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4001: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.7850e-04\n",
            "Epoch 4002/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4002: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 4003/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.8870e-04\n",
            "Epoch 4003: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8749e-04\n",
            "Epoch 4004/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2130e-04\n",
            "Epoch 4004: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4165e-04\n",
            "Epoch 4005/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5016e-04\n",
            "Epoch 4005: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 4006/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4006: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 4007/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.8961e-04\n",
            "Epoch 4007: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.2690e-04\n",
            "Epoch 4008/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7307e-04\n",
            "Epoch 4008: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8468e-04\n",
            "Epoch 4009/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7291e-04\n",
            "Epoch 4009: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4731e-04\n",
            "Epoch 4010/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.7241e-04\n",
            "Epoch 4010: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.4496e-04\n",
            "Epoch 4011/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4011: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 4012/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4705e-04\n",
            "Epoch 4012: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.1261e-04\n",
            "Epoch 4013/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1775e-04\n",
            "Epoch 4013: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1710e-04\n",
            "Epoch 4014/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4014: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0010\n",
            "Epoch 4015/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8685e-04\n",
            "Epoch 4015: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.6825e-04\n",
            "Epoch 4016/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9074e-04\n",
            "Epoch 4016: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.1710e-04\n",
            "Epoch 4017/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9425e-04\n",
            "Epoch 4017: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.9416e-04\n",
            "Epoch 4018/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4018: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1192e-04\n",
            "Epoch 4019/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7150e-04\n",
            "Epoch 4019: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9547e-04\n",
            "Epoch 4020/4500\n",
            "\n",
            "Epoch 4035: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0024\n",
            "Epoch 4036/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0049\n",
            "Epoch 4036: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0047\n",
            "Epoch 4037/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 4037: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0038\n",
            "Epoch 4038/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0078\n",
            "Epoch 4038: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0078\n",
            "Epoch 4039/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 4039: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0049\n",
            "Epoch 4040/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0057\n",
            "Epoch 4040: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0067\n",
            "Epoch 4041/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0075\n",
            "Epoch 4041: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0060\n",
            "Epoch 4042/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0106\n",
            "Epoch 4042: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0107\n",
            "Epoch 4043/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0043\n",
            "Epoch 4043: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0045\n",
            "Epoch 4044/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0138\n",
            "Epoch 4044: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0104\n",
            "Epoch 4045/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045\n",
            "Epoch 4045: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0069\n",
            "Epoch 4046/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0112\n",
            "Epoch 4046: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0067\n",
            "Epoch 4047/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0075\n",
            "Epoch 4047: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0090\n",
            "Epoch 4048/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 4048: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0040\n",
            "Epoch 4049/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 4049: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0037\n",
            "Epoch 4050/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 4050: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0055\n",
            "Epoch 4051/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 4051: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 4052/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045\n",
            "Epoch 4052: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0040\n",
            "Epoch 4053/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 4053: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0038\n",
            "Epoch 4054/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 4054: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 4055/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0044\n",
            "Epoch 4055: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0033\n",
            "Epoch 4056/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 4056: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0035\n",
            "Epoch 4057/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 4057: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "Epoch 4058/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 4058: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 4059/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0054\n",
            "Epoch 4059: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0043\n",
            "Epoch 4060/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4060: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0028\n",
            "Epoch 4061/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4061: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 4062/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 4062: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 4063/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4063: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 4064/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4064: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 4065/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4065: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 4066/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 4066: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 4067/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4067: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 4068/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4068: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0010\n",
            "Epoch 4069/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.5907e-04\n",
            "Epoch 4069: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9645e-04\n",
            "Epoch 4070/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.1302e-04\n",
            "Epoch 4070: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4156e-04\n",
            "Epoch 4071/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2405e-04\n",
            "Epoch 4071: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9216e-04\n",
            "Epoch 4072/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8989e-04\n",
            "Epoch 4072: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4264e-04\n",
            "Epoch 4073/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7810e-04\n",
            "Epoch 4073: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.2989e-04\n",
            "Epoch 4074/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2486e-04\n",
            "Epoch 4074: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2712e-04\n",
            "Epoch 4075/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9662e-04\n",
            "Epoch 4075: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2095e-04\n",
            "Epoch 4076/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4220e-04\n",
            "Epoch 4076: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.3541e-04\n",
            "Epoch 4077/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1234e-04\n",
            "Epoch 4077: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5078e-04\n",
            "Epoch 4078/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3865e-04\n",
            "Epoch 4078: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.5259e-04\n",
            "Epoch 4079/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7829e-04\n",
            "Epoch 4079: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5131e-04\n",
            "Epoch 4080/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2994e-04\n",
            "Epoch 4080: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4501e-04\n",
            "Epoch 4081/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4350e-04\n",
            "Epoch 4081: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.2641e-04\n",
            "Epoch 4082/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.3118e-04\n",
            "Epoch 4082: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7501e-04\n",
            "Epoch 4083/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2382e-04\n",
            "Epoch 4083: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.5207e-04\n",
            "Epoch 4084/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4797e-04\n",
            "Epoch 4084: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.1818e-04\n",
            "Epoch 4085/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.3366e-04\n",
            "Epoch 4085: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5499e-04\n",
            "Epoch 4086/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8848e-04\n",
            "Epoch 4086: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1661e-04\n",
            "Epoch 4087/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1185e-04\n",
            "Epoch 4087: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.4768e-04\n",
            "Epoch 4088/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6826e-04\n",
            "Epoch 4088: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.5868e-04\n",
            "Epoch 4089/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0804e-04\n",
            "Epoch 4089: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7022e-04\n",
            "Epoch 4090/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7509e-04\n",
            "Epoch 4090: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.1573e-04\n",
            "Epoch 4091/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4266e-04\n",
            "Epoch 4091: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.0954e-04\n",
            "Epoch 4092/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2956e-04\n",
            "Epoch 4092: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3199e-04\n",
            "Epoch 4093/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5828e-04\n",
            "Epoch 4093: loss did not improve from 0.00030\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8566e-04\n",
            "Epoch 4094/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5502e-04\n",
            "Epoch 4094: loss improved from 0.00030 to 0.00027, saving model to weights\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.6766e-04\n",
            "Epoch 4095/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.0842e-04\n",
            "Epoch 4095: loss did not improve from 0.00027\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3082e-04\n",
            "Epoch 4096/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6404e-04\n",
            "Epoch 4096: loss did not improve from 0.00027\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1218e-04\n",
            "Epoch 4097/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.2221e-04\n",
            "Epoch 4097: loss did not improve from 0.00027\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.3430e-04\n",
            "Epoch 4098/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2449e-04\n",
            "Epoch 4098: loss did not improve from 0.00027\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.7307e-04\n",
            "Epoch 4099/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4901e-04\n",
            "Epoch 4099: loss improved from 0.00027 to 0.00026, saving model to weights\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.5583e-04\n",
            "Epoch 4100/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.7148e-04\n",
            "Epoch 4100: loss improved from 0.00026 to 0.00023, saving model to weights\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2667e-04\n",
            "Epoch 4101/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.3478e-04\n",
            "Epoch 4101: loss did not improve from 0.00023\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2933e-04\n",
            "Epoch 4102/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6968e-04\n",
            "Epoch 4102: loss improved from 0.00023 to 0.00021, saving model to weights\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.1257e-04\n",
            "Epoch 4103/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.7346e-04\n",
            "Epoch 4103: loss improved from 0.00021 to 0.00021, saving model to weights\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.0740e-04\n",
            "Epoch 4104/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4161e-04\n",
            "Epoch 4104: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.3479e-04\n",
            "Epoch 4105/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.9916e-04\n",
            "Epoch 4105: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.4480e-04\n",
            "Epoch 4106/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3782e-04\n",
            "Epoch 4106: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.0187e-04\n",
            "Epoch 4107/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.0417e-04\n",
            "Epoch 4107: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.5750e-04\n",
            "Epoch 4108/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1293e-04\n",
            "Epoch 4108: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.2753e-04\n",
            "Epoch 4109/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9067e-04\n",
            "Epoch 4109: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.1251e-04\n",
            "Epoch 4110/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9645e-04\n",
            "Epoch 4110: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.2030e-04\n",
            "Epoch 4111/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.8092e-04\n",
            "Epoch 4111: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3688e-04\n",
            "Epoch 4112/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1493e-04\n",
            "Epoch 4112: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4435e-04\n",
            "Epoch 4113/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2582e-04\n",
            "Epoch 4113: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.0051e-04\n",
            "Epoch 4114/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4520e-04\n",
            "Epoch 4114: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7754e-04\n",
            "Epoch 4115/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7932e-04\n",
            "Epoch 4115: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.2751e-04\n",
            "Epoch 4116/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9514e-04\n",
            "Epoch 4116: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.4059e-04\n",
            "Epoch 4117/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8432e-04\n",
            "Epoch 4117: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.2681e-04\n",
            "Epoch 4118/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2207e-04\n",
            "Epoch 4118: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.9080e-04\n",
            "Epoch 4119/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9563e-04\n",
            "Epoch 4119: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.1443e-04\n",
            "Epoch 4120/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3005e-04\n",
            "Epoch 4120: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.0893e-04\n",
            "Epoch 4121/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9913e-04\n",
            "Epoch 4121: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.4432e-04\n",
            "Epoch 4122/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7499e-04\n",
            "Epoch 4122: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.6630e-04\n",
            "Epoch 4123/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5227e-04\n",
            "Epoch 4123: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.2296e-04\n",
            "Epoch 4124/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7229e-04\n",
            "Epoch 4124: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.3715e-04\n",
            "Epoch 4125/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.9970e-04\n",
            "Epoch 4125: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5278e-04\n",
            "Epoch 4126/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4112e-04\n",
            "Epoch 4126: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.6398e-04\n",
            "Epoch 4127/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0739e-04\n",
            "Epoch 4127: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.3491e-04\n",
            "Epoch 4128/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4559e-04\n",
            "Epoch 4128: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5801e-04\n",
            "Epoch 4129/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1313e-04\n",
            "Epoch 4129: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9259e-04\n",
            "Epoch 4130/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9109e-04\n",
            "Epoch 4130: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.9090e-04\n",
            "Epoch 4131/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4131: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 4132/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5743e-04\n",
            "Epoch 4132: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0157e-04\n",
            "Epoch 4133/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4133: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2228e-04\n",
            "Epoch 4134/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4134: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 4135/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6261e-04\n",
            "Epoch 4135: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9652e-04\n",
            "Epoch 4136/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4136: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7733e-04\n",
            "Epoch 4137/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4137: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 4138/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2345e-04\n",
            "Epoch 4138: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6019e-04\n",
            "Epoch 4139/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4139: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 4140/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.6775e-04\n",
            "Epoch 4140: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 4141/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3163e-04\n",
            "Epoch 4141: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 4142/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 4142: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 4143/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4143: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 4144/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4144: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 4145/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 4145: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 4146/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 4146: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0031\n",
            "Epoch 4147/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4147: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 4148/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4148: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 4149/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4149: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 4150/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4150: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 4151/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1198e-04\n",
            "Epoch 4151: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8910e-04\n",
            "Epoch 4152/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4152: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5364e-04\n",
            "Epoch 4153/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6154e-04\n",
            "Epoch 4153: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0268e-04\n",
            "Epoch 4154/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6294e-04\n",
            "Epoch 4154: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3808e-04\n",
            "Epoch 4155/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3743e-04\n",
            "Epoch 4155: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8426e-04\n",
            "Epoch 4156/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7424e-04\n",
            "Epoch 4156: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.3195e-04\n",
            "Epoch 4157/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3514e-04\n",
            "Epoch 4157: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.0241e-04\n",
            "Epoch 4158/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0744e-04\n",
            "Epoch 4158: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.3347e-04\n",
            "Epoch 4159/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7572e-04\n",
            "Epoch 4159: loss did not improve from 0.00021\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.2028e-04\n",
            "Epoch 4160/4500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.7601e-04\n",
            "Epoch 4175/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.8396e-04\n",
            "Epoch 4175: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0295e-04\n",
            "Epoch 4176/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5652e-04\n",
            "Epoch 4176: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8010e-04\n",
            "Epoch 4177/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9188e-04\n",
            "Epoch 4177: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3281e-04\n",
            "Epoch 4178/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6614e-04\n",
            "Epoch 4178: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.7709e-04\n",
            "Epoch 4179/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3590e-04\n",
            "Epoch 4179: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.1556e-04\n",
            "Epoch 4180/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2903e-04\n",
            "Epoch 4180: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.8851e-04\n",
            "Epoch 4181/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7645e-04\n",
            "Epoch 4181: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.7354e-04\n",
            "Epoch 4182/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.5725e-04\n",
            "Epoch 4182: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.0781e-04\n",
            "Epoch 4183/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.6916e-04\n",
            "Epoch 4183: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.9130e-04\n",
            "Epoch 4184/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9637e-04\n",
            "Epoch 4184: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.5764e-04\n",
            "Epoch 4185/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8375e-04\n",
            "Epoch 4185: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.8406e-04\n",
            "Epoch 4186/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.5464e-04\n",
            "Epoch 4186: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.9914e-04\n",
            "Epoch 4187/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3191e-04\n",
            "Epoch 4187: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4063e-04\n",
            "Epoch 4188/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8082e-04\n",
            "Epoch 4188: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4747e-04\n",
            "Epoch 4189/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8643e-04\n",
            "Epoch 4189: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0309e-04\n",
            "Epoch 4190/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2511e-04\n",
            "Epoch 4190: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1800e-04\n",
            "Epoch 4191/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4191: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 4192/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7103e-04\n",
            "Epoch 4192: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8964e-04\n",
            "Epoch 4193/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4193: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 4194/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4092e-04\n",
            "Epoch 4194: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6654e-04\n",
            "Epoch 4195/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4195: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0010\n",
            "Epoch 4196/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5706e-04\n",
            "Epoch 4196: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0714e-04\n",
            "Epoch 4197/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9623e-04\n",
            "Epoch 4197: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.8274e-04\n",
            "Epoch 4198/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4198: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 4199/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5914e-04\n",
            "Epoch 4199: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.4662e-04\n",
            "Epoch 4200/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9267e-04\n",
            "Epoch 4200: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4010e-04\n",
            "Epoch 4201/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0585e-04\n",
            "Epoch 4201: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9246e-04\n",
            "Epoch 4202/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4202: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2171e-04\n",
            "Epoch 4203/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0532e-04\n",
            "Epoch 4203: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 4204/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.6253e-04\n",
            "Epoch 4204: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7401e-04\n",
            "Epoch 4205/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4205: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 4206/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2128e-04\n",
            "Epoch 4206: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8022e-04\n",
            "Epoch 4207/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.1931e-04\n",
            "Epoch 4207: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8730e-04\n",
            "Epoch 4208/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5215e-04\n",
            "Epoch 4208: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.6672e-04\n",
            "Epoch 4209/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8133e-04\n",
            "Epoch 4209: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.8865e-04\n",
            "Epoch 4210/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4240e-04\n",
            "Epoch 4210: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4408e-04\n",
            "Epoch 4211/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4541e-04\n",
            "Epoch 4211: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7124e-04\n",
            "Epoch 4212/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.6419e-04\n",
            "Epoch 4212: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9570e-04\n",
            "Epoch 4213/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3247e-04\n",
            "Epoch 4213: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6862e-04\n",
            "Epoch 4214/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1377e-04\n",
            "Epoch 4214: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6373e-04\n",
            "Epoch 4215/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7454e-04\n",
            "Epoch 4215: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.2217e-04\n",
            "Epoch 4216/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8198e-04\n",
            "Epoch 4216: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6092e-04\n",
            "Epoch 4217/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4217: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0011\n",
            "Epoch 4218/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5658e-04\n",
            "Epoch 4218: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.3969e-04\n",
            "Epoch 4219/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2316e-04\n",
            "Epoch 4219: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.6478e-04\n",
            "Epoch 4220/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5362e-04\n",
            "Epoch 4220: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4798e-04\n",
            "Epoch 4221/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4221: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8518e-04\n",
            "Epoch 4222/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4278e-04\n",
            "Epoch 4222: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6714e-04\n",
            "Epoch 4223/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0471e-04\n",
            "Epoch 4223: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.0857e-04\n",
            "Epoch 4224/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.6577e-04\n",
            "Epoch 4224: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.4935e-04\n",
            "Epoch 4225/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4225: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 4226/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3023e-04\n",
            "Epoch 4226: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.1439e-04\n",
            "Epoch 4227/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4227: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 4228/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7065e-04\n",
            "Epoch 4228: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5997e-04\n",
            "Epoch 4229/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.3210e-04\n",
            "Epoch 4229: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.1143e-04\n",
            "Epoch 4230/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9015e-04\n",
            "Epoch 4230: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4278e-04\n",
            "Epoch 4231/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5666e-04\n",
            "Epoch 4231: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.0783e-04\n",
            "Epoch 4232/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4722e-04\n",
            "Epoch 4232: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1685e-04\n",
            "Epoch 4233/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4665e-04\n",
            "Epoch 4233: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.2237e-04\n",
            "Epoch 4234/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5113e-04\n",
            "Epoch 4234: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.0386e-04\n",
            "Epoch 4235/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.6242e-04\n",
            "Epoch 4235: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5411e-04\n",
            "Epoch 4236/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5286e-04\n",
            "Epoch 4236: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.8721e-04\n",
            "Epoch 4237/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0932e-04\n",
            "Epoch 4237: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9138e-04\n",
            "Epoch 4238/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8475e-04\n",
            "Epoch 4238: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6267e-04\n",
            "Epoch 4239/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2303e-04\n",
            "Epoch 4239: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0657e-04\n",
            "Epoch 4240/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3640e-04\n",
            "Epoch 4240: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.9268e-04\n",
            "Epoch 4241/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6133e-04\n",
            "Epoch 4241: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3959e-04\n",
            "Epoch 4242/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5115e-04\n",
            "Epoch 4242: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.7539e-04\n",
            "Epoch 4243/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3363e-04\n",
            "Epoch 4243: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9507e-04\n",
            "Epoch 4244/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9867e-04\n",
            "Epoch 4244: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.9414e-04\n",
            "Epoch 4245/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2173e-04\n",
            "Epoch 4245: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.4857e-04\n",
            "Epoch 4246/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8601e-04\n",
            "Epoch 4246: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.6896e-04\n",
            "Epoch 4247/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3281e-04\n",
            "Epoch 4247: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.4112e-04\n",
            "Epoch 4248/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6318e-04\n",
            "Epoch 4248: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.0875e-04\n",
            "Epoch 4249/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0635e-04\n",
            "Epoch 4249: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0873e-04\n",
            "Epoch 4250/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0991e-04\n",
            "Epoch 4250: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3893e-04\n",
            "Epoch 4251/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3165e-04\n",
            "Epoch 4251: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.6389e-04\n",
            "Epoch 4252/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7215e-04\n",
            "Epoch 4252: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.4107e-04\n",
            "Epoch 4253/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.8046e-04\n",
            "Epoch 4253: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.4859e-04\n",
            "Epoch 4254/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.1972e-04\n",
            "Epoch 4254: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.8454e-04\n",
            "Epoch 4255/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8722e-04\n",
            "Epoch 4255: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.4835e-04\n",
            "Epoch 4256/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3839e-04\n",
            "Epoch 4256: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6295e-04\n",
            "Epoch 4257/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1497e-04\n",
            "Epoch 4257: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3330e-04\n",
            "Epoch 4258/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8140e-04\n",
            "Epoch 4258: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.6873e-04\n",
            "Epoch 4259/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8144e-04\n",
            "Epoch 4259: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.5097e-04\n",
            "Epoch 4260/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3883e-04\n",
            "Epoch 4260: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.2570e-04\n",
            "Epoch 4261/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9805e-04\n",
            "Epoch 4261: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.0938e-04\n",
            "Epoch 4262/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9532e-04\n",
            "Epoch 4262: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5042e-04\n",
            "Epoch 4263/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9909e-04\n",
            "Epoch 4263: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8218e-04\n",
            "Epoch 4264/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3775e-04\n",
            "Epoch 4264: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.9449e-04\n",
            "Epoch 4265/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3391e-04\n",
            "Epoch 4265: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.5964e-04\n",
            "Epoch 4266/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9278e-04\n",
            "Epoch 4266: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8364e-04\n",
            "Epoch 4267/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7597e-04\n",
            "Epoch 4267: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.2392e-04\n",
            "Epoch 4268/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.0859e-04\n",
            "Epoch 4268: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.6423e-04\n",
            "Epoch 4269/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8400e-04\n",
            "Epoch 4269: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.8782e-04\n",
            "Epoch 4270/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.0246e-04\n",
            "Epoch 4270: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.1800e-04\n",
            "Epoch 4271/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.1178e-04\n",
            "Epoch 4271: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.7195e-04\n",
            "Epoch 4272/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2580e-04\n",
            "Epoch 4272: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0315e-04\n",
            "Epoch 4273/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9669e-04\n",
            "Epoch 4273: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.3750e-04\n",
            "Epoch 4274/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6558e-04\n",
            "Epoch 4274: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.2957e-04\n",
            "Epoch 4275/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5217e-04\n",
            "Epoch 4275: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.7275e-04\n",
            "Epoch 4276/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9463e-04\n",
            "Epoch 4276: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.1135e-04\n",
            "Epoch 4277/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5191e-04\n",
            "Epoch 4277: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5012e-04\n",
            "Epoch 4278/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.3759e-04\n",
            "Epoch 4278: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3973e-04\n",
            "Epoch 4279/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5943e-04\n",
            "Epoch 4279: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0808e-04\n",
            "Epoch 4280/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.1565e-04\n",
            "Epoch 4280: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.4147e-04\n",
            "Epoch 4281/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7600e-04\n",
            "Epoch 4281: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.7196e-04\n",
            "Epoch 4282/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5092e-04\n",
            "Epoch 4282: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9371e-04\n",
            "Epoch 4283/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6494e-04\n",
            "Epoch 4283: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5851e-04\n",
            "Epoch 4284/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.0825e-04\n",
            "Epoch 4284: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.0431e-04\n",
            "Epoch 4285/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8059e-04\n",
            "Epoch 4285: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.6951e-04\n",
            "Epoch 4286/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.9008e-04\n",
            "Epoch 4286: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7008e-04\n",
            "Epoch 4287/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5634e-04\n",
            "Epoch 4287: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.1794e-04\n",
            "Epoch 4288/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7592e-04\n",
            "Epoch 4288: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.7614e-04\n",
            "Epoch 4289/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5151e-04\n",
            "Epoch 4289: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0180e-04\n",
            "Epoch 4290/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4190e-04\n",
            "Epoch 4290: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0781e-04\n",
            "Epoch 4291/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4943e-04\n",
            "Epoch 4291: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.7034e-04\n",
            "Epoch 4292/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8207e-04\n",
            "Epoch 4292: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0948e-04\n",
            "Epoch 4293/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2761e-04\n",
            "Epoch 4293: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.3609e-04\n",
            "Epoch 4294/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3183e-04\n",
            "Epoch 4294: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.3964e-04\n",
            "Epoch 4295/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7509e-04\n",
            "Epoch 4295: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8468e-04\n",
            "Epoch 4296/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8853e-04\n",
            "Epoch 4296: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6427e-04\n",
            "Epoch 4297/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8043e-04\n",
            "Epoch 4297: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.5095e-04\n",
            "Epoch 4298/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4298: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9371e-04\n",
            "Epoch 4299/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.2599e-04\n",
            "Epoch 4299: loss did not improve from 0.00018\n",
            "Epoch 4330/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0097e-04\n",
            "Epoch 4330: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1653e-04\n",
            "Epoch 4331/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4331: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5152e-04\n",
            "Epoch 4332/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.5673e-04\n",
            "Epoch 4332: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0010\n",
            "Epoch 4333/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4333: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.3525e-04\n",
            "Epoch 4334/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4334: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 4335/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4335: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5300e-04\n",
            "Epoch 4336/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6968e-04\n",
            "Epoch 4336: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1311e-04\n",
            "Epoch 4337/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4337: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.4214e-04\n",
            "Epoch 4338/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.8683e-04\n",
            "Epoch 4338: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 4339/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7960e-04\n",
            "Epoch 4339: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.2811e-04\n",
            "Epoch 4340/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4340: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4341/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.6066e-04\n",
            "Epoch 4341: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.5586e-04\n",
            "Epoch 4342/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4342: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.4059e-04\n",
            "Epoch 4343/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8548e-04\n",
            "Epoch 4343: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5122e-04\n",
            "Epoch 4344/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4344: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 4345/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4345: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0019\n",
            "Epoch 4346/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4346: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 4347/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4630e-04\n",
            "Epoch 4347: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0010\n",
            "Epoch 4348/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4348: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4054e-04\n",
            "Epoch 4349/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0901e-04\n",
            "Epoch 4349: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 4350/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3760e-04\n",
            "Epoch 4350: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.2225e-04\n",
            "Epoch 4351/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1441e-04\n",
            "Epoch 4351: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3703e-04\n",
            "Epoch 4352/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2461e-04\n",
            "Epoch 4352: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.2413e-04\n",
            "Epoch 4353/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9907e-04\n",
            "Epoch 4353: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.9431e-04\n",
            "Epoch 4354/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4618e-04\n",
            "Epoch 4354: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.2577e-04\n",
            "Epoch 4355/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4355: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.3862e-04\n",
            "Epoch 4356/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7432e-04\n",
            "Epoch 4356: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.1163e-04\n",
            "Epoch 4357/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4357: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0098e-04\n",
            "Epoch 4358/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5363e-04\n",
            "Epoch 4358: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.4777e-04\n",
            "Epoch 4359/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4359: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4904e-04\n",
            "Epoch 4360/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1771e-04\n",
            "Epoch 4360: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4270e-04\n",
            "Epoch 4361/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4361: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 4362/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2220e-04\n",
            "Epoch 4362: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.8115e-04\n",
            "Epoch 4363/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4363: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.6842e-04\n",
            "Epoch 4364/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5592e-04\n",
            "Epoch 4364: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 4365/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0445e-04\n",
            "Epoch 4365: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.6760e-04\n",
            "Epoch 4366/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8807e-04\n",
            "Epoch 4366: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4243e-04\n",
            "Epoch 4367/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5393e-04\n",
            "Epoch 4367: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6922e-04\n",
            "Epoch 4368/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1326e-04\n",
            "Epoch 4368: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.5805e-04\n",
            "Epoch 4369/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4682e-04\n",
            "Epoch 4369: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.7906e-04\n",
            "Epoch 4370/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8616e-04\n",
            "Epoch 4370: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0986e-04\n",
            "Epoch 4371/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8848e-04\n",
            "Epoch 4371: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 4.4376e-04\n",
            "Epoch 4372/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9819e-04\n",
            "Epoch 4372: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.4339e-04\n",
            "Epoch 4373/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7182e-04\n",
            "Epoch 4373: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.6593e-04\n",
            "Epoch 4374/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5957e-04\n",
            "Epoch 4374: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0246e-04\n",
            "Epoch 4375/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0708e-04\n",
            "Epoch 4375: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7576e-04\n",
            "Epoch 4376/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5128e-04\n",
            "Epoch 4376: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7181e-04\n",
            "Epoch 4377/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9912e-04\n",
            "Epoch 4377: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.9802e-04\n",
            "Epoch 4378/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4896e-04\n",
            "Epoch 4378: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8204e-04\n",
            "Epoch 4379/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0021e-04\n",
            "Epoch 4379: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0406e-04\n",
            "Epoch 4380/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9068e-04\n",
            "Epoch 4380: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.2226e-04\n",
            "Epoch 4381/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4724e-04\n",
            "Epoch 4381: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6656e-04\n",
            "Epoch 4382/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8834e-04\n",
            "Epoch 4382: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6554e-04\n",
            "Epoch 4383/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8727e-04\n",
            "Epoch 4383: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.1351e-04\n",
            "Epoch 4384/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4384: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 4385/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3899e-04\n",
            "Epoch 4385: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7275e-04\n",
            "Epoch 4386/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7075e-04\n",
            "Epoch 4386: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.3560e-04\n",
            "Epoch 4387/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9010e-04\n",
            "Epoch 4387: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.3905e-04\n",
            "Epoch 4388/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2801e-04\n",
            "Epoch 4388: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.3745e-04\n",
            "Epoch 4389/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8820e-04\n",
            "Epoch 4389: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5176e-04\n",
            "Epoch 4390/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4035e-04\n",
            "Epoch 4390: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.7077e-04\n",
            "Epoch 4391/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1049e-04\n",
            "Epoch 4391: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.5727e-04\n",
            "Epoch 4392/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5170e-04\n",
            "Epoch 4392: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.2557e-04\n",
            "Epoch 4393/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1486e-04\n",
            "Epoch 4393: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.2178e-04\n",
            "Epoch 4394/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1433e-04\n",
            "Epoch 4394: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4978e-04\n",
            "Epoch 4395/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9731e-04\n",
            "Epoch 4395: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0493e-04\n",
            "Epoch 4396/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4396: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0010\n",
            "Epoch 4397/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4196e-04\n",
            "Epoch 4397: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7788e-04\n",
            "Epoch 4398/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 4398: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0020\n",
            "Epoch 4399/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4399: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0014\n",
            "Epoch 4400/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 4400: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 4401/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4401: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 4402/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 4402: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0031\n",
            "Epoch 4403/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4403: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 4404/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 4404: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 4405/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9299e-04\n",
            "Epoch 4405: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0011\n",
            "Epoch 4406/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 4406: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 4407/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4407: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0013\n",
            "Epoch 4408/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 4408: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 4409/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4409: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 4410/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0047\n",
            "Epoch 4410: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0036\n",
            "Epoch 4411/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4411: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0026\n",
            "Epoch 4412/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 4412: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 4413/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4413: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0020\n",
            "Epoch 4414/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4414: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4415/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 4415: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0018\n",
            "Epoch 4416/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4416: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 4417/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4417: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4418/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4418: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 4419/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4419: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 4420/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 4420: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 4421/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 4421: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 4422/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 4422: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "Epoch 4423/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4423: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 4424/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 4424: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0027\n",
            "Epoch 4425/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4425: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 4426/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 4426: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 4427/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4427: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4428/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4428: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 4429/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4429: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4430/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4430: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0014\n",
            "Epoch 4431/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4431: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0013\n",
            "Epoch 4432/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4432: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 4433/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.3624e-04\n",
            "Epoch 4433: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 4434/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 4434: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "Epoch 4435/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 4435: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0021\n",
            "Epoch 4436/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4436: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 4437/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 4437: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 4438/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 4438: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0037\n",
            "Epoch 4439/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4439: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 4440/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 4440: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0037\n",
            "Epoch 4441/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 4441: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0035\n",
            "Epoch 4442/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 4442: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0026\n",
            "Epoch 4443/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 4443: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0036\n",
            "Epoch 4444/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 4444: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0041\n",
            "Epoch 4445/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0086\n",
            "Epoch 4445: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0058\n",
            "Epoch 4446/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0061\n",
            "Epoch 4446: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0088\n",
            "Epoch 4447/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0069\n",
            "Epoch 4447: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0049\n",
            "Epoch 4448/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0145\n",
            "Epoch 4448: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0142\n",
            "Epoch 4449/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 4449: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0043\n",
            "Epoch 4450/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0107\n",
            "Epoch 4450: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0071\n",
            "Epoch 4451/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 4451: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0042\n",
            "Epoch 4452/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 4452: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 4453/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0051\n",
            "Epoch 4453: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 4454/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 4454: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.6257e-04\n",
            "Epoch 4496/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.5563e-04\n",
            "Epoch 4496: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.4819e-04\n",
            "Epoch 4497/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4646e-04\n",
            "Epoch 4497: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5519e-04\n",
            "Epoch 4498/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1360e-04\n",
            "Epoch 4498: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5398e-04\n",
            "Epoch 4499/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1137e-04\n",
            "Epoch 4499: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1096e-04\n",
            "Epoch 4500/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9274e-04\n",
            "Epoch 4500: loss did not improve from 0.00018\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.5432e-04\n",
            "32/32 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# learning is noisy, keep best parameters during training\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights\",\n",
        "    save_weights_only=True, monitor=\"loss\", verbose=1, save_best_only=True\n",
        ")\n",
        "history = ODE_model.fit(x_train, y_train, epochs=4500, batch_size=100,\n",
        "    callbacks=[checkpoint])\n",
        "ODE_model.load_weights(\"weights\")\n",
        "\n",
        "x = np.linspace(0,30,1000)\n",
        "y = y(x)\n",
        "y_prime = y_prime(x)\n",
        "y_yprime = ODE_model.predict(x) # first axis is y(t), second axis is yprime(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5d5sz5FyHBM"
      },
      "source": [
        "* Plot trained output against analytic harmonic oscillator solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "Gk6RNf5yyGdU",
        "outputId": "2cabaf9e-655f-4cd1-8392-3fb6affae88c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0019de8a90>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(6,4))\n",
        "c1 = \"#1F77B4\"\n",
        "c2 = \"#E25140\"\n",
        "plt.subplots_adjust(left=0.12, right=0.95, top=0.95, hspace=0.6)\n",
        "\n",
        "ax = plt.subplot(3, 1, 1)\n",
        "ax.annotate('(a)', xycoords=\"axes fraction\", xy=(-0.13,0.9))\n",
        "plt.xlabel(\"$t$\")\n",
        "plt.ylabel(\"$y(t)$\")\n",
        "plt.plot(x, y, color=c1, label=\"Analytic\")\n",
        "plt.plot(x, y_yprime[:,0], color=c2, linestyle=\"dotted\", label=\"Neural ODE $y(t)$\")\n",
        "plt.legend(loc='upper right', frameon=False, ncol=2)\n",
        "\n",
        "ax = plt.subplot(3, 1, 2)\n",
        "ax.annotate('(b)', xycoords=\"axes fraction\", xy=(-0.13,0.9))\n",
        "plt.xlabel(\"$t$\")\n",
        "plt.ylabel(\"$y'(t)$\")\n",
        "plt.plot(x, y_prime, color=c1, label=\"Analytic\")\n",
        "plt.plot(x, y_yprime[:,1], color=c2, linestyle=\"dotted\", label=\"$y'(t)$\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}