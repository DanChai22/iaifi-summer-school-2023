{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Neural ODEs for Lattice Field Theory**\n",
        "---\n",
        "\n",
        "Let us stare at this screenshot from Prof. Miranda Cheng's talk.\n",
        "![picture](https://drive.google.com/uc?export=view&id=1CrbOMDeMZVTHcdFtGjeza6dVmEWZOGCg)\n",
        "Suppose, we want to train a Neural Network perfectly, such that inputs are $x, y \\in V_L$ on lattice, and outputs are $\\phi_x \\sim e^{- S[\\phi]}$, sampled from a target lattice field theory, with action\n",
        "$$S[\\phi] = \\sum\\limits_{x,y \\in V_L} \\phi_x \\Delta_{x,y} \\phi_y + \\sum\\limits_{x \\in V_L} (m^2 \\phi_x^2 + \\lambda \\phi_x^4).$$\n",
        "\n",
        "Such a perfectly trained Neural Network can be recast as an ODE\n",
        "$$\\frac{d}{dt}\\phi(t)_x = v_{\\theta}(\\phi(t), t, \\lambda)_x,$$\n",
        "where ODE time $t \\in \\{0, \\cdots , T \\}$ corresponds to hidden layers. This ODE transforms Neural Network input $z:= z(0)$ to the desired output $\\phi_x \\sim e^{-S[\\phi]}$.\n",
        "* Here, $z:= z(0)$ are Lattice points $x,y \\in V_L$.\n",
        "* When the number of hidden layers is large, and training step size is infinitesimally small, all hidden layers post-training are represented by conitnuous function $v_{\\theta}$, instead of usual convention of weights and biases.\n",
        "* Such a perfectly trained Neural Network, which acts as a vector field between $z(0)$ and $z(T)$, is called a *Neural ODE*."
      ],
      "metadata": {
        "id": "N34ruOtNeQ1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From generic Neural Networks to Neural ODEs**\n",
        "----\n",
        "\n",
        "> [Reference paper](https://arxiv.org/pdf/1806.07366.pdf)\n",
        ">\n",
        ">A Neural ODE acts as a vector field between initial state $z(0)$ and target state $z(T)$.  \n",
        ">\n",
        "<!-- ![picture](https://drive.google.com/uc?export=view&id=1gI0Thz0PiGYfaH0M6a0aeO0zKAkZCu3v) -->\n",
        ">\n",
        "\n",
        "The following ODE\n",
        "$$\\frac{dz}{dt} = v_{\\theta}(z,t),~~ z(0) = z,~~z(T)=\\phi_x.$$\n",
        "can be solved using Euler's method, where the ODE time is discretized into $n$ time-steps. The solution to this ODE, at any time step $t_{n+1}$, is\n",
        "$$z_{n+1} = z_n + v_{\\theta}(z_n, t_n) \\cdot(t_{n+1} - t_n), $$\n",
        "for $z_i := z(t_i).$"
      ],
      "metadata": {
        "id": "USQGMXLBCxT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We are interested in training a Neural Network to generate a Neural ODE *for any given problem.***\n",
        "---\n",
        " To do that, we need some familiarity with ODE Solver functions inbuilt in python libraries commonly used to design Neural Networks.\n",
        "\n",
        " Let us introduce an ODE solver function called ```odeint``` from ```jax.experimental.ode``` Library.\n",
        "----\n",
        "\n",
        "This function\n",
        "$$\\text{odeint}(v_{\\theta}, z_n, \\text{array}(t_0, t_T), \\theta_{t_n})$$\n",
        "\n",
        "results in a tuple of the form (initial state $z_0$, target state $z_T$). In the context of Neural ODEs, $\\theta_{t_n}$ are the network parameters of the $n^{\\text{th}}$ hidden layer, and get updated via training.  \n",
        "\n",
        "\n",
        ">Then, we need to define a loss function $L()$ that can be used to train a randomly initialized Network to produce a Neural ODE corresponding to a given problem. Consider the following loss function\n",
        "$$L(\\,z(t_{n+1})\\,) = L \\Big( \\, z(t_n) + \\int^{t_{n+1}}_{t_n} v_{\\theta_{t_n}}(z_{t_n} , t_n , \\theta_{t_n}) \\, \\Big) . $$\n",
        "> The input to this loss function is an ODE solver of the form $\\text{ODESolve}(z_{t_n}, v_{\\theta_{t_n}}, t_n , t_{n+1})$."
      ],
      "metadata": {
        "id": "T2R8OdNZDbu_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1PoFEfjcpHm"
      },
      "source": [
        "**Example 0**\n",
        "---\n",
        "\n",
        "Consider initial state $z(0)=x$, and target state $z(T)=x^3 + 0.1x$. We want to construct a Neural ODE, starting from a simple fully connected feedforward Neural Network, using the loss function defined above. The trained Neural Network / the Neural ODE would correspond to a vector field $f: z(0) \\to z(T)$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given below are the steps to get this Neural ODE. Some of these steps are left as exercises.\n",
        "---"
      ],
      "metadata": {
        "id": "uJSygMjWQVg5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mL9c10Gd7JG"
      },
      "source": [
        "* First, we import necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t3vrVctMetz"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "import numpy.random as nprand\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "from jax.experimental.ode import odeint\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffoIG0a5jK1X"
      },
      "source": [
        "* Let us define the initial and final (target) states, $$z(0)=0, \\\\ z(T)=x^3 + 0.1x,$$ respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfmBQ7REjOb_",
        "outputId": "1e2742c0-fa39-48b7-a0b7-eedbae63551c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "input = jnp.reshape(jnp.linspace(-2.5, 2.5, 15), (15, 1))\n",
        "target = input**3 + 0.1 * input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4qdq4lllofa"
      },
      "source": [
        "* We want to draw initial Network parameters $\\theta$ randomly, and update these through training. Given below is a function to draw parameters randomly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CevNj4ptl06R"
      },
      "outputs": [],
      "source": [
        "def init_random_params( N, rng=nprand.RandomState(0)): # N denotes the size or width of each hidden layer of the Neural ODE that we want\n",
        "    return [(rng.randn(p, q), rng.randn(q))\n",
        "            for p, q, in zip(N[:-1], N[1:])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnVwYAzpcMry"
      },
      "source": [
        "* Next, we want to define $f: z(0) \\to z(T)$ as a fully connected feedforward Network. To do that, we define a function ```fcn``` that creates a fully connected feedforward Network from input ```xs``` and parameters $\\theta$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fcn(theta, xs):\n",
        "    for w, b in theta:\n",
        "      outputs = jnp.dot(xs, w) + b  # Linear transformation\n",
        "      xs = jnp.tanh(outputs)        # Nonlinearity; we can choose ReLU or other nonlinearities as well\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "oja0NlXdMJ3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 0: Define the function $v_{\\theta_{t_n}}(z_{t_n}, t_n, \\theta_{t_n})$.**\n",
        "---\n"
      ],
      "metadata": {
        "id": "01oAoYlrVl6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution (to be removed before GitHub upload)**\n",
        "---"
      ],
      "metadata": {
        "id": "A9JSPdSPYWQP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbjkB-P3cbw0"
      },
      "outputs": [],
      "source": [
        "def v_theta(z_n, t_n, theta_t_n):\n",
        "    f_arguments = jnp.hstack([z_n, jnp.array(t_n)])\n",
        "    return fcn(theta_t_n, f_arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwBnxisddJsg"
      },
      "source": [
        "**Exercise 1: Define the function $z_{t_{n+1}} = \\text{ODESolve}(z_{t_n}, v_{\\theta_{t_n}}, t_n , t_{n+1})$.**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution (to be removed before GitHub upload)**\n",
        "---"
      ],
      "metadata": {
        "id": "Lb3VPF_QZMWP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbDb5Sd9dbvG"
      },
      "outputs": [],
      "source": [
        "def ODESolve(theta_t_n, z_n):\n",
        "    t0_tT = jnp.array([0.0, 1.0]) # define a tuple of start and end times.\n",
        "    z0, zT = odeint(v_theta, z_n, t0_tT, theta_t_n)\n",
        "    return zT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxIQyeSAeGuz"
      },
      "source": [
        "**Exercise 2: Use function ODESolve to define a quadratic loss function. Call it ```NODE_L2loss```.**\n",
        "---\n",
        "\n",
        "Use the following tips.\n",
        "* Function ```vmap``` can be used to apply function ODESolve to its inputs in a vectorized manner. E.g. ```batched_ODESolve = vmap(ODESolve, in_axes=(None, 0))```\n",
        "* Function ```batched_ODESolve``` takes in two arguments: network parameters, and network input. Network output is ```batched_ODESolve(theta, xs)```.\n",
        "* We define the quadratic loss as $L_2 = (z_{t_{n+1}} - z_T)^2$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution (to be removed before GitHub upload)**\n",
        "----"
      ],
      "metadata": {
        "id": "WiJwYmhybwQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batched_ODESolve = vmap(ODESolve, in_axes=(None, 0))"
      ],
      "metadata": {
        "id": "xm9FWiweZ3TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVNC24A4eGQK"
      },
      "outputs": [],
      "source": [
        "def NODE_L2loss(theta, xs, ys):\n",
        "    f_x = batched_ODESolve(theta, xs)\n",
        "    return jnp.mean(jnp.sum((f_x - ys)**2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMMTUI2Le8EO"
      },
      "source": [
        "**Next,**\n",
        "---\n",
        "\n",
        "* We define a simple gradient descent optimizer, using this loss. Let's call this loss function as ```NODE_L2loss```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_Wup8cjfA5l"
      },
      "outputs": [],
      "source": [
        "def NODE_gd(theta, xs, ys):\n",
        "    gradients = grad(NODE_L2loss)(theta, xs, ys)\n",
        "    return [(w - step_size * dw, b - step_size * db)\n",
        "            for (w, b), (dw, db) in zip(theta, gradients)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSzcNCNAgbx6"
      },
      "source": [
        "* Next, using function ```init_random_params```, we initialize parameters $\\theta$ for a fully connected feedforward Network (one that we intend to optimize enough to create a Neural ODE)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This requires defining Network hyperparameters."
      ],
      "metadata": {
        "id": "j2pU_3xNEIUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NODE_width = [2, 20, 1] # layer sizes\n",
        "step_size = 0.0005 # size of training steps\n",
        "train_iters = 1000 # number of training steps\n",
        "\n",
        "NODE_theta = init_random_params(NODE_width)"
      ],
      "metadata": {
        "id": "Ul09ykm3ELw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Using these, we initialize the Network, and update it until Network input and output are $z(0)=x$ and $z(T) = x^3 + 0.1x$, respectively.\n",
        "\n"
      ],
      "metadata": {
        "id": "4ALhFdnUF6pL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Note that $T=2$; and layer sizes at $t=0,1,2$ are $N=2,20,1$, respectively."
      ],
      "metadata": {
        "id": "vv7AWwsyMPa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(train_iters):\n",
        "    NODE_theta = NODE_gd(NODE_theta, input, target)"
      ],
      "metadata": {
        "id": "KM8l2ik-K9UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This Neural Network is now a Neural ODE, representing a continuous transformation from inputs $z(0)$ to outputs $z(T)$.  "
      ],
      "metadata": {
        "id": "wRe-qe7UK-fL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Let us test the efficiency of this Neural ODE for a different choice of inputs."
      ],
      "metadata": {
        "id": "qAWTnLm8MkBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6, 4), dpi=150)\n",
        "ax = fig.gca()\n",
        "ax.scatter(input, target, lw=0.5, color='red')\n",
        "new_inputs = jnp.reshape(jnp.linspace(-3.0, 3.0, 300), (300, 1))\n",
        "ax.plot(new_inputs, batched_ODESolve(NODE_theta, new_inputs), lw=0.5, color='green')\n",
        "ax.set_xlabel('input')\n",
        "ax.set_ylabel('output')\n",
        "plt.legend(('Neural ODE'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "VwgbjrMwLdmI",
        "outputId": "fe790819-afd1-45a1-82e6-d29dae53641c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7a185d526da0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj7u5qeRl9Jv"
      },
      "source": [
        "**Example 1: Simple Harmonic Oscillator**\n",
        "----\n",
        "\n",
        "Consider the differential equation\n",
        "$$m \\, y''(t) + k\\, y(t) =0,$$\n",
        "for $m= 1.4$, $k=1.9$ (in appropriate units), and boundary conditions are\n",
        "$$y(0)=1.2~,~ y(0.47)=0.09~,~y'(1)=0.$$\n",
        "\n",
        "> The analytical solution (via Mathematica) is $$y(t) = 0.043576 \\cos(1.16496 \\, t) + 0.101414 \\sin(1.16496 \\, t)   .$$\n",
        "\n",
        "We want to train a Neural Network such that its input and output after training are $t$ and $y(t)$, respectively. Such a trained Network would be a Neural ODE for this one-dimensional simple harmonic oscillator.\n",
        "\n",
        "> To do so, we first note that, *any arbitrary ODE of order $n$* for some scalar function $y(t)$\n",
        "$$G\\big(y(t), y'(t), y''(t), \\cdots , y^{(n)}(t),t \\big) = 0,$$\n",
        "can be mapped into **a system of first order ODEs**\n",
        "$$y'_1(t) = y_2(t),\\\\\n",
        "y'_2(t) = y_3(t), \\\\\n",
        "\\vdots \\\\\n",
        "y'_n(t) = G^*\\big(y(t), y'(t), y''(t), \\cdots , y^{(n)}(t),t \\big).\n",
        "$$\n",
        "Here, $G^*$ is obtained by solving $G$ for $y^{(n)}(t)$.\n",
        "\n",
        "Our simple harmonic oscillator problem is a second order ODE. That can be recast as two joint first order ODEs. The trained Network, i.e. the Neural ODE, will produce a tuple made from $\\big(y'(t), y(t) \\big)$ as its output.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal here is to train a Neural Network to get this Neural ODE. This is broken into several steps. We will walk you through some of these steps, and leave some as exercises.\n",
        "----"
      ],
      "metadata": {
        "id": "Q_fOj-MzQiFy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byu6LhAhsIKb"
      },
      "source": [
        "* First, we import necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfAdUfQwrueb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TjSPJgPsLUw"
      },
      "source": [
        "**Exercise 3: Define two functions $y(t)$ and $y'(t)$ for final (target) states of the Neural ODE.**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution (to be removed before GitHub upload)**\n",
        "---"
      ],
      "metadata": {
        "id": "ddRJaO4XROaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# harmonic oscillator solution y(t)\n",
        "def y(t):\n",
        "    return 0.043576*np.cos(1.16496*t) + 0.101414*np.sin(1.16496*t)\n",
        "# first derivative of y(t)\n",
        "def y_prime(t):\n",
        "    return 0.118144*np.cos(1.16496*t) - 0.0507645*np.sin(1.16496*t)"
      ],
      "metadata": {
        "id": "RhOO0ZToRbdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next,**\n",
        "---\n",
        "* We generate Neural ODE initial state $t$ and final state $(y(t), y'(t))$ using functions ```y(t)``` and ```y'(t)```, defined above."
      ],
      "metadata": {
        "id": "8AGwNU8ERewk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZebrJBNfrwaC"
      },
      "outputs": [],
      "source": [
        "input = np.random.rand(200)*30\n",
        "target = np.array([y(input), y_prime(input)]).T # y and y_prime here are the functions for y(t) and y'(t), respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9SXBxLVtJfY"
      },
      "source": [
        "* Then, we design a simple Neural Network with tanh activation function, each layer size 100, and use MSE loss and Adam optimizer to compile it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5lBVS8HtZoo"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "ODE_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=tf.nn.tanh, input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(100, activation=tf.nn.tanh),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])\n",
        "# compile it\n",
        "ODE_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    loss=tf.keras.losses.MeanSquaredError()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o2YUgZcuSLF"
      },
      "source": [
        "* Now that we have initialized this network, we want to train this to get Neural ODE for the simple harmonic oscillator problem."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* First, learning is noisy, and we want to save the best parameters during training to use for future predictions. To do so, we define ```checkpoint``` below."
      ],
      "metadata": {
        "id": "bBFvinxPTL3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights\",\n",
        "    save_weights_only=True, monitor=\"loss\", verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "slFuSEtOTVcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Then train this model on input $t$ and target data $y(t), y'(t)$. We save the training history below.  "
      ],
      "metadata": {
        "id": "wryjR4RCTg1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = ODE_model.fit(input, target, epochs=4500, batch_size=100,\n",
        "    callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV4Cr5BETsIt",
        "outputId": "0e69dafc-8a90-476f-b33d-3ba1510b8ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3154: loss did not improve from 0.00246\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0029\n",
            "Epoch 3155/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3155: loss did not improve from 0.00246\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 3156/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3156: loss did not improve from 0.00246\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0031\n",
            "Epoch 3157/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3157: loss did not improve from 0.00246\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 3158/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3158: loss did not improve from 0.00246\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0029\n",
            "Epoch 3159/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3159: loss did not improve from 0.00246\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 3160/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3160: loss improved from 0.00246 to 0.00244, saving model to weights\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0024\n",
            "Epoch 3161/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3161: loss did not improve from 0.00244\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0025\n",
            "Epoch 3162/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3162: loss improved from 0.00244 to 0.00240, saving model to weights\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0024\n",
            "Epoch 3163/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3163: loss did not improve from 0.00240\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0026\n",
            "Epoch 3164/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3164: loss improved from 0.00240 to 0.00232, saving model to weights\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0023\n",
            "Epoch 3165/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3165: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 3166/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3166: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 3167/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3167: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 3168/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3168: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0032\n",
            "Epoch 3169/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3169: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3170/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3170: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 3171/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3171: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0035\n",
            "Epoch 3172/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3172: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3173/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3173: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0026\n",
            "Epoch 3174/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3174: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0028\n",
            "Epoch 3175/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3175: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0026\n",
            "Epoch 3176/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3176: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0026\n",
            "Epoch 3177/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3177: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 3178/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3178: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 3179/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3179: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0036\n",
            "Epoch 3180/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3180: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 3181/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3181: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0034\n",
            "Epoch 3182/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3182: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 3183/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3183: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "Epoch 3184/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 3184: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "Epoch 3185/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3185: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "Epoch 3186/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3186: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "Epoch 3187/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3187: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0041\n",
            "Epoch 3188/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0065\n",
            "Epoch 3188: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0045\n",
            "Epoch 3189/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0071\n",
            "Epoch 3189: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0066\n",
            "Epoch 3190/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3190: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0058\n",
            "Epoch 3191/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046\n",
            "Epoch 3191: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0048\n",
            "Epoch 3192/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3192: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0042\n",
            "Epoch 3193/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0081\n",
            "Epoch 3193: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0053\n",
            "Epoch 3194/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0055\n",
            "Epoch 3194: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0044\n",
            "Epoch 3195/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0044\n",
            "Epoch 3195: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0048\n",
            "Epoch 3196/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3196: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0048\n",
            "Epoch 3197/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3197: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0047\n",
            "Epoch 3198/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3198: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0042\n",
            "Epoch 3199/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3199: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0036\n",
            "Epoch 3200/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045\n",
            "Epoch 3200: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0034\n",
            "Epoch 3201/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0043\n",
            "Epoch 3201: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0036\n",
            "Epoch 3202/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3202: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0035\n",
            "Epoch 3203/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3203: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0035\n",
            "Epoch 3204/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3204: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 3205/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3205: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0037\n",
            "Epoch 3206/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3206: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0033\n",
            "Epoch 3207/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046\n",
            "Epoch 3207: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0035\n",
            "Epoch 3208/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0053\n",
            "Epoch 3208: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0046\n",
            "Epoch 3209/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3209: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0037\n",
            "Epoch 3210/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3210: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0032\n",
            "Epoch 3211/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3211: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3212/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3212: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0029\n",
            "Epoch 3213/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3213: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0038\n",
            "Epoch 3214/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3214: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0043\n",
            "Epoch 3215/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 3215: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "Epoch 3216/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3216: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0035\n",
            "Epoch 3217/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3217: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0036\n",
            "Epoch 3218/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3218: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0032\n",
            "Epoch 3219/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3219: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3220/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0053\n",
            "Epoch 3220: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0041\n",
            "Epoch 3221/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0043\n",
            "Epoch 3221: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0044\n",
            "Epoch 3222/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046\n",
            "Epoch 3222: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0046\n",
            "Epoch 3223/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3223: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0041\n",
            "Epoch 3224/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3224: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0034\n",
            "Epoch 3225/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3225: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0030\n",
            "Epoch 3226/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3226: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0030\n",
            "Epoch 3227/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3227: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0029\n",
            "Epoch 3228/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3228: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0032\n",
            "Epoch 3229/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3229: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0034\n",
            "Epoch 3230/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046\n",
            "Epoch 3230: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0036\n",
            "Epoch 3231/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3231: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0042\n",
            "Epoch 3232/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3232: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 3233/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3233: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 3234/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3234: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0035\n",
            "Epoch 3235/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3235: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 3236/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3236: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0037\n",
            "Epoch 3237/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3237: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 3238/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3238: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3239/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3239: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 3240/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3240: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 3241/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3241: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0031\n",
            "Epoch 3242/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3242: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0035\n",
            "Epoch 3243/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3243: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0040\n",
            "Epoch 3244/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0044\n",
            "Epoch 3244: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0032\n",
            "Epoch 3245/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3245: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0037\n",
            "Epoch 3246/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3246: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0034\n",
            "Epoch 3247/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3247: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0032\n",
            "Epoch 3248/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045\n",
            "Epoch 3248: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0040\n",
            "Epoch 3249/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3249: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0035\n",
            "Epoch 3250/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3250: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 3251/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3251: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0032\n",
            "Epoch 3252/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3252: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "Epoch 3253/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3253: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0031\n",
            "Epoch 3254/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3254: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 3255/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0055\n",
            "Epoch 3255: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0046\n",
            "Epoch 3256/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3256: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0038\n",
            "Epoch 3257/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3257: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0032\n",
            "Epoch 3258/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3258: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 3259/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0054\n",
            "Epoch 3259: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0047\n",
            "Epoch 3260/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3260: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0041\n",
            "Epoch 3261/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3261: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0048\n",
            "Epoch 3262/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0051\n",
            "Epoch 3262: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0043\n",
            "Epoch 3263/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 3263: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0044\n",
            "Epoch 3264/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3264: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0040\n",
            "Epoch 3265/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0054\n",
            "Epoch 3265: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0040\n",
            "Epoch 3266/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0063\n",
            "Epoch 3266: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0050\n",
            "Epoch 3267/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3267: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0056\n",
            "Epoch 3268/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3268: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0040\n",
            "Epoch 3269/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3269: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0041\n",
            "Epoch 3270/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0081\n",
            "Epoch 3270: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0057\n",
            "Epoch 3271/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 3271: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0048\n",
            "Epoch 3272/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3272: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0038\n",
            "Epoch 3273/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3273: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 3274/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3274: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 3275/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3275: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0026\n",
            "Epoch 3276/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3276: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0028\n",
            "Epoch 3277/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3277: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0034\n",
            "Epoch 3278/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3278: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0036\n",
            "Epoch 3279/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3279: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 3280/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3280: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0029\n",
            "Epoch 3281/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3281: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 3282/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3282: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3283/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3283: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0027\n",
            "Epoch 3284/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3284: loss did not improve from 0.00232\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 3285/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3285: loss improved from 0.00232 to 0.00220, saving model to weights\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0022\n",
            "Epoch 3286/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3286: loss improved from 0.00220 to 0.00215, saving model to weights\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0022\n",
            "Epoch 3287/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3287: loss did not improve from 0.00215\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 3288/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3288: loss improved from 0.00215 to 0.00208, saving model to weights\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0021\n",
            "Epoch 3289/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3289: loss improved from 0.00208 to 0.00205, saving model to weights\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0021\n",
            "Epoch 3290/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3290: loss did not improve from 0.00205\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3291/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3291: loss improved from 0.00205 to 0.00200, saving model to weights\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0020\n",
            "Epoch 3292/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3292: loss improved from 0.00200 to 0.00199, saving model to weights\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0020\n",
            "Epoch 3293/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3293: loss did not improve from 0.00199\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0024\n",
            "Epoch 3294/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3294: loss did not improve from 0.00199\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3295/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3295: loss did not improve from 0.00199\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 3296/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3296: loss did not improve from 0.00199\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0022\n",
            "Epoch 3297/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3297: loss did not improve from 0.00199\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3298/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3298: loss did not improve from 0.00199\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 3299/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3299: loss did not improve from 0.00199\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3300/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3300: loss did not improve from 0.00199\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3301/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3301: loss improved from 0.00199 to 0.00190, saving model to weights\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0019\n",
            "Epoch 3302/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3302: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3303/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3303: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3304/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3304: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3305/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3305: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3306/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3306: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 3307/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3307: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 3308/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3308: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 3309/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3309: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3310/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3310: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0039\n",
            "Epoch 3311/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3311: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0039\n",
            "Epoch 3312/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0051\n",
            "Epoch 3312: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "Epoch 3313/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3313: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0051\n",
            "Epoch 3314/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3314: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0034\n",
            "Epoch 3315/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0048\n",
            "Epoch 3315: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0036\n",
            "Epoch 3316/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3316: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 3317/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3317: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0045\n",
            "Epoch 3318/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3318: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0036\n",
            "Epoch 3319/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3319: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0036\n",
            "Epoch 3320/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3320: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3321/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3321: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 3322/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3322: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0035\n",
            "Epoch 3323/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3323: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0039\n",
            "Epoch 3324/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3324: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0033\n",
            "Epoch 3325/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3325: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "Epoch 3326/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0053\n",
            "Epoch 3326: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 3327/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0059\n",
            "Epoch 3327: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0050\n",
            "Epoch 3328/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0061\n",
            "Epoch 3328: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0056\n",
            "Epoch 3329/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0049\n",
            "Epoch 3329: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0043\n",
            "Epoch 3330/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3330: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0035\n",
            "Epoch 3331/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045\n",
            "Epoch 3331: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0042\n",
            "Epoch 3332/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3332: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0036\n",
            "Epoch 3333/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3333: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0033\n",
            "Epoch 3334/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3334: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0032\n",
            "Epoch 3335/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3335: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0039\n",
            "Epoch 3336/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3336: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 3337/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0050\n",
            "Epoch 3337: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0049\n",
            "Epoch 3338/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3338: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3339/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3339: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 3340/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3340: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0032\n",
            "Epoch 3341/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3341: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0030\n",
            "Epoch 3342/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3342: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 3343/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3343: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0024\n",
            "Epoch 3344/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0040\n",
            "Epoch 3344: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 3345/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3345: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3346/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3346: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 3347/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3347: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 3348/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3348: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 3349/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3349: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0023\n",
            "Epoch 3350/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3350: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0028\n",
            "Epoch 3351/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3351: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0026\n",
            "Epoch 3352/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3352: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0022\n",
            "Epoch 3353/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3353: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 3354/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3354: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3355/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3355: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 3356/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3356: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 3357/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3357: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 3358/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3358: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3359/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3359: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 3360/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3360: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 3361/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3361: loss did not improve from 0.00190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3362/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3362: loss improved from 0.00190 to 0.00163, saving model to weights\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0016\n",
            "Epoch 3363/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3363: loss did not improve from 0.00163\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 3364/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3364: loss did not improve from 0.00163\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3365/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3365: loss did not improve from 0.00163\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3366/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3366: loss improved from 0.00163 to 0.00160, saving model to weights\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0016\n",
            "Epoch 3367/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3367: loss improved from 0.00160 to 0.00147, saving model to weights\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0015\n",
            "Epoch 3368/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3368: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3369/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3369: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3370/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3370: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0028\n",
            "Epoch 3371/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3371: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3372/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3372: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0028\n",
            "Epoch 3373/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3373: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 3374/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3374: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3375/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3375: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3376/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3376: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3377/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3377: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3378/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3378: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3379/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3379: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0016\n",
            "Epoch 3380/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3380: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 3381/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3381: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3382/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3382: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0035\n",
            "Epoch 3383/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3383: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0029\n",
            "Epoch 3384/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3384: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0027\n",
            "Epoch 3385/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0044\n",
            "Epoch 3385: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0034\n",
            "Epoch 3386/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3386: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 3387/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3387: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 3388/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3388: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3389/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3389: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "Epoch 3390/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3390: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0025\n",
            "Epoch 3391/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3391: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3392/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3392: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3393/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3393: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0032\n",
            "Epoch 3394/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3394: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0028\n",
            "Epoch 3395/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0048\n",
            "Epoch 3395: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0043\n",
            "Epoch 3396/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3396: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3397/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3397: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0024\n",
            "Epoch 3398/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0043\n",
            "Epoch 3398: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0035\n",
            "Epoch 3399/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3399: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0031\n",
            "Epoch 3400/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3400: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 3401/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3401: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0029\n",
            "Epoch 3402/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3402: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 3403/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3403: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 3404/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3404: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 3405/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3405: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 3406/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3406: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3407/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3407: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0018\n",
            "Epoch 3408/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3408: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3409/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3409: loss did not improve from 0.00147\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 3410/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3410: loss improved from 0.00147 to 0.00141, saving model to weights\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0014\n",
            "Epoch 3411/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3411: loss did not improve from 0.00141\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 3412/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3412: loss did not improve from 0.00141\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 3413/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3413: loss did not improve from 0.00141\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 3414/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3414: loss did not improve from 0.00141\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 3415/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3415: loss did not improve from 0.00141\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 3416/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3416: loss improved from 0.00141 to 0.00134, saving model to weights\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0013\n",
            "Epoch 3417/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3417: loss improved from 0.00134 to 0.00134, saving model to weights\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0013\n",
            "Epoch 3418/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3418: loss improved from 0.00134 to 0.00128, saving model to weights\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0013\n",
            "Epoch 3419/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3419: loss did not improve from 0.00128\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0022\n",
            "Epoch 3420/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3420: loss did not improve from 0.00128\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3421/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3421: loss improved from 0.00128 to 0.00113, saving model to weights\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0011\n",
            "Epoch 3422/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3422: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3423/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3423: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 3424/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3424: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3425/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3425: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3426/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3426: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 3427/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3427: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3428/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3428: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3429/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3429: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 3430/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3430: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3431/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3431: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0022\n",
            "Epoch 3432/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3432: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0027\n",
            "Epoch 3433/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3433: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0040\n",
            "Epoch 3434/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3434: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0031\n",
            "Epoch 3435/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 3435: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0030\n",
            "Epoch 3436/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3436: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0026\n",
            "Epoch 3437/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3437: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0029\n",
            "Epoch 3438/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3438: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 3439/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3439: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 3440/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3440: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3441/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3441: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3442/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3442: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 3443/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3443: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 3444/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3444: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3445/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3445: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 3446/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 3446: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0034\n",
            "Epoch 3447/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3447: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 3448/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0051\n",
            "Epoch 3448: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0039\n",
            "Epoch 3449/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3449: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 3450/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3450: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3451/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3451: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 3452/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3452: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 3453/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3453: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 3454/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3454: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 3455/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3455: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3456/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3456: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3457/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3457: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 3458/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3458: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0019\n",
            "Epoch 3459/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3459: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 3460/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3460: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 3461/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3461: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 3462/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3462: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 3463/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3463: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 3464/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 3464: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0031\n",
            "Epoch 3465/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3465: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 3466/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3466: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3467/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3467: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 3468/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3468: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0019\n",
            "Epoch 3469/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3469: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 3470/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3470: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 3471/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3471: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 3472/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.5721e-04\n",
            "Epoch 3472: loss did not improve from 0.00113\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 3473/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.8838e-04\n",
            "Epoch 3473: loss improved from 0.00113 to 0.00105, saving model to weights\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0011\n",
            "Epoch 3474/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3474: loss did not improve from 0.00105\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0017\n",
            "Epoch 3475/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3475: loss did not improve from 0.00105\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0017\n",
            "Epoch 3476/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3476: loss did not improve from 0.00105\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0014\n",
            "Epoch 3477/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3477: loss did not improve from 0.00105\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 3478/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3478: loss did not improve from 0.00105\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 3479/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3479: loss improved from 0.00105 to 0.00103, saving model to weights\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0010\n",
            "Epoch 3480/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3480: loss did not improve from 0.00103\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "Epoch 3481/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.4504e-04\n",
            "Epoch 3481: loss improved from 0.00103 to 0.00101, saving model to weights\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0010\n",
            "Epoch 3482/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3482: loss did not improve from 0.00101\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 3483/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2258e-04\n",
            "Epoch 3483: loss did not improve from 0.00101\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 3484/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.4949e-04\n",
            "Epoch 3484: loss improved from 0.00101 to 0.00092, saving model to weights\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 9.2208e-04\n",
            "Epoch 3485/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2847e-04\n",
            "Epoch 3485: loss improved from 0.00092 to 0.00077, saving model to weights\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 7.6589e-04\n",
            "Epoch 3486/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9252e-04\n",
            "Epoch 3486: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0010\n",
            "Epoch 3487/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0490e-04\n",
            "Epoch 3487: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4823e-04\n",
            "Epoch 3488/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3488: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7354e-04\n",
            "Epoch 3489/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3489: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3490/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1532e-04\n",
            "Epoch 3490: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4870e-04\n",
            "Epoch 3491/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3491: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6937e-04\n",
            "Epoch 3492/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4622e-04\n",
            "Epoch 3492: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 3493/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3493: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0010\n",
            "Epoch 3494/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3494: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4748e-04\n",
            "Epoch 3495/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0223e-04\n",
            "Epoch 3495: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.8832e-04\n",
            "Epoch 3496/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1163e-04\n",
            "Epoch 3496: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.6382e-04\n",
            "Epoch 3497/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3497: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4656e-04\n",
            "Epoch 3498/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.3310e-04\n",
            "Epoch 3498: loss did not improve from 0.00077\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.0156e-04\n",
            "Epoch 3499/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.5658e-04\n",
            "Epoch 3499: loss improved from 0.00077 to 0.00072, saving model to weights\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 7.2437e-04\n",
            "Epoch 3500/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3500: loss did not improve from 0.00072\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1817e-04\n",
            "Epoch 3501/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.3514e-04\n",
            "Epoch 3501: loss did not improve from 0.00072\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2929e-04\n",
            "Epoch 3502/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1584e-04\n",
            "Epoch 3502: loss improved from 0.00072 to 0.00069, saving model to weights\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 6.8595e-04\n",
            "Epoch 3503/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1107e-04\n",
            "Epoch 3503: loss did not improve from 0.00069\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4826e-04\n",
            "Epoch 3504/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7114e-04\n",
            "Epoch 3504: loss did not improve from 0.00069\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1391e-04\n",
            "Epoch 3505/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.8606e-04\n",
            "Epoch 3505: loss did not improve from 0.00069\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8991e-04\n",
            "Epoch 3506/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4152e-04\n",
            "Epoch 3506: loss did not improve from 0.00069\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.9510e-04\n",
            "Epoch 3507/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2569e-04\n",
            "Epoch 3507: loss did not improve from 0.00069\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7304e-04\n",
            "Epoch 3508/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6370e-04\n",
            "Epoch 3508: loss did not improve from 0.00069\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1112e-04\n",
            "Epoch 3509/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0590e-04\n",
            "Epoch 3509: loss did not improve from 0.00069\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3822e-04\n",
            "Epoch 3510/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3510: loss did not improve from 0.00069\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4984e-04\n",
            "Epoch 3511/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2097e-04\n",
            "Epoch 3511: loss did not improve from 0.00069\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3864e-04\n",
            "Epoch 3512/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3738e-04\n",
            "Epoch 3512: loss improved from 0.00069 to 0.00064, saving model to weights\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 6.4174e-04\n",
            "Epoch 3513/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2890e-04\n",
            "Epoch 3513: loss did not improve from 0.00064\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.4583e-04\n",
            "Epoch 3514/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7784e-04\n",
            "Epoch 3514: loss did not improve from 0.00064\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8947e-04\n",
            "Epoch 3515/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0072e-04\n",
            "Epoch 3515: loss improved from 0.00064 to 0.00058, saving model to weights\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.7605e-04\n",
            "Epoch 3516/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4107e-04\n",
            "Epoch 3516: loss improved from 0.00058 to 0.00057, saving model to weights\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.6918e-04\n",
            "Epoch 3517/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4215e-04\n",
            "Epoch 3517: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1121e-04\n",
            "Epoch 3518/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9601e-04\n",
            "Epoch 3518: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2270e-04\n",
            "Epoch 3519/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3519: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 3520/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4756e-04\n",
            "Epoch 3520: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5245e-04\n",
            "Epoch 3521/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3521: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.7054e-04\n",
            "Epoch 3522/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8927e-04\n",
            "Epoch 3522: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2111e-04\n",
            "Epoch 3523/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3523: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.9101e-04\n",
            "Epoch 3524/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7403e-04\n",
            "Epoch 3524: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3525/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3525: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3526/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3526: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 3527/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3527: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 3528/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3528: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 3529/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.5322e-04\n",
            "Epoch 3529: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3530/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3530: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 3531/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3531: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0013\n",
            "Epoch 3532/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0209e-04\n",
            "Epoch 3532: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0010\n",
            "Epoch 3533/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3533: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.9907e-04\n",
            "Epoch 3534/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3534: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 3535/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7315e-04\n",
            "Epoch 3535: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6147e-04\n",
            "Epoch 3536/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3536: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4881e-04\n",
            "Epoch 3537/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1972e-04\n",
            "Epoch 3537: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5724e-04\n",
            "Epoch 3538/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3538: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 3539/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.4903e-04\n",
            "Epoch 3539: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3540/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3540: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3030e-04\n",
            "Epoch 3541/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6846e-04\n",
            "Epoch 3541: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1229e-04\n",
            "Epoch 3542/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7394e-04\n",
            "Epoch 3542: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1775e-04\n",
            "Epoch 3543/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3952e-04\n",
            "Epoch 3543: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7772e-04\n",
            "Epoch 3544/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8622e-04\n",
            "Epoch 3544: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1513e-04\n",
            "Epoch 3545/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7712e-04\n",
            "Epoch 3545: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8143e-04\n",
            "Epoch 3546/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2137e-04\n",
            "Epoch 3546: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.9422e-04\n",
            "Epoch 3547/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.8586e-04\n",
            "Epoch 3547: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9032e-04\n",
            "Epoch 3548/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1061e-04\n",
            "Epoch 3548: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 3549/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2185e-04\n",
            "Epoch 3549: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3543e-04\n",
            "Epoch 3550/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.9973e-04\n",
            "Epoch 3550: loss did not improve from 0.00057\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6558e-04\n",
            "Epoch 3551/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1740e-04\n",
            "Epoch 3551: loss improved from 0.00057 to 0.00056, saving model to weights\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 5.5525e-04\n",
            "Epoch 3552/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.5770e-04\n",
            "Epoch 3552: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1508e-04\n",
            "Epoch 3553/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.9227e-04\n",
            "Epoch 3553: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4793e-04\n",
            "Epoch 3554/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8343e-04\n",
            "Epoch 3554: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2914e-04\n",
            "Epoch 3555/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3555: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 3556/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9224e-04\n",
            "Epoch 3556: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3557/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3557: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0016\n",
            "Epoch 3558/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3558: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0011\n",
            "Epoch 3559/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3559: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.7898e-04\n",
            "Epoch 3560/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3560: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3561/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.8766e-04\n",
            "Epoch 3561: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.6430e-04\n",
            "Epoch 3562/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3562: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 3563/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3563: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 3564/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3564: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0025\n",
            "Epoch 3565/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3565: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 3566/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3566: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 3567/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3567: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0022\n",
            "Epoch 3568/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0051\n",
            "Epoch 3568: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0041\n",
            "Epoch 3569/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3569: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3570/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3570: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3571/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3571: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0030\n",
            "Epoch 3572/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3572: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 3573/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3573: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0017\n",
            "Epoch 3574/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3574: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3575/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3575: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 3576/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3576: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3577/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3577: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0020\n",
            "Epoch 3578/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3578: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3579/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3579: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 3580/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3580: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3581/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3581: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 3582/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 3582: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 3583/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3583: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0031\n",
            "Epoch 3584/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3584: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0016\n",
            "Epoch 3585/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3585: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 3586/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3586: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3587/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3587: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 3588/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3588: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "Epoch 3589/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3589: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 3590/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3401e-04\n",
            "Epoch 3590: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3591/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3591: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 3592/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3592: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0015\n",
            "Epoch 3593/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3593: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "Epoch 3594/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3594: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4818e-04\n",
            "Epoch 3595/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3595: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 3596/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5269e-04\n",
            "Epoch 3596: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.6237e-04\n",
            "Epoch 3597/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.9843e-04\n",
            "Epoch 3597: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.8324e-04\n",
            "Epoch 3598/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5751e-04\n",
            "Epoch 3598: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.8458e-04\n",
            "Epoch 3599/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3599: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3250e-04\n",
            "Epoch 3600/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.8635e-04\n",
            "Epoch 3600: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.9070e-04\n",
            "Epoch 3601/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5856e-04\n",
            "Epoch 3601: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8917e-04\n",
            "Epoch 3602/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4938e-04\n",
            "Epoch 3602: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.4146e-04\n",
            "Epoch 3603/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.3576e-04\n",
            "Epoch 3603: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3604/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0735e-04\n",
            "Epoch 3604: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2320e-04\n",
            "Epoch 3605/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2752e-04\n",
            "Epoch 3605: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9737e-04\n",
            "Epoch 3606/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6542e-04\n",
            "Epoch 3606: loss did not improve from 0.00056\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.8346e-04\n",
            "Epoch 3607/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5983e-04\n",
            "Epoch 3607: loss improved from 0.00056 to 0.00055, saving model to weights\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 5.4588e-04\n",
            "Epoch 3608/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9173e-04\n",
            "Epoch 3608: loss improved from 0.00055 to 0.00043, saving model to weights\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 4.3116e-04\n",
            "Epoch 3609/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4277e-04\n",
            "Epoch 3609: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.4671e-04\n",
            "Epoch 3610/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2014e-04\n",
            "Epoch 3610: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.8063e-04\n",
            "Epoch 3611/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7064e-04\n",
            "Epoch 3611: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.1239e-04\n",
            "Epoch 3612/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2051e-04\n",
            "Epoch 3612: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6996e-04\n",
            "Epoch 3613/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6228e-04\n",
            "Epoch 3613: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7334e-04\n",
            "Epoch 3614/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3614: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2361e-04\n",
            "Epoch 3615/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3615: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3672/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3672: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0014\n",
            "Epoch 3673/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3673: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0019\n",
            "Epoch 3674/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3674: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 3675/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3675: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.6538e-04\n",
            "Epoch 3676/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7947e-04\n",
            "Epoch 3676: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9972e-04\n",
            "Epoch 3677/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3677: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 3678/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3678: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3679/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3679: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 3680/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3680: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0022\n",
            "Epoch 3681/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3681: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 3682/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3682: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0022\n",
            "Epoch 3683/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3683: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3684/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0042\n",
            "Epoch 3684: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0035\n",
            "Epoch 3685/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3685: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 3686/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0062\n",
            "Epoch 3686: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0048\n",
            "Epoch 3687/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0048\n",
            "Epoch 3687: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0048\n",
            "Epoch 3688/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0071\n",
            "Epoch 3688: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0051\n",
            "Epoch 3689/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 3689: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0035\n",
            "Epoch 3690/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3690: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0045\n",
            "Epoch 3691/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3691: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3692/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 3692: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 3693/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 3693: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0020\n",
            "Epoch 3694/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3694: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 3695/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3695: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3696/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3696: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 3697/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 3697: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 3698/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3698: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0026\n",
            "Epoch 3699/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3699: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 3700/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 3700: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0027\n",
            "Epoch 3701/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3701: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 3702/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3702: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0029\n",
            "Epoch 3703/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3703: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0023\n",
            "Epoch 3704/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3704: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0017\n",
            "Epoch 3705/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3705: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0019\n",
            "Epoch 3706/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3706: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 3707/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 3707: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 3708/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3708: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0033\n",
            "Epoch 3709/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0047\n",
            "Epoch 3709: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0034\n",
            "Epoch 3710/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0067\n",
            "Epoch 3710: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0084\n",
            "Epoch 3711/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3711: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0046\n",
            "Epoch 3712/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0073\n",
            "Epoch 3712: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0045\n",
            "Epoch 3713/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0053\n",
            "Epoch 3713: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0058\n",
            "Epoch 3714/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3714: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0037\n",
            "Epoch 3715/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 3715: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0030\n",
            "Epoch 3716/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0063\n",
            "Epoch 3716: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0042\n",
            "Epoch 3717/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 3717: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0042\n",
            "Epoch 3718/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3718: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 3719/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3719: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 3720/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3720: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 3721/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3721: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 3722/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3722: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0022\n",
            "Epoch 3723/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.7955e-04\n",
            "Epoch 3723: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0013\n",
            "Epoch 3724/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3724: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3725/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3725: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 3726/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4870e-04\n",
            "Epoch 3726: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0011\n",
            "Epoch 3727/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3727: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 3728/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.5182e-04\n",
            "Epoch 3728: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0013\n",
            "Epoch 3729/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3729: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 3730/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3730: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 3731/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3731: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0014\n",
            "Epoch 3732/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3732: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 3733/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7903e-04\n",
            "Epoch 3733: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.1946e-04\n",
            "Epoch 3734/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3734: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.5336e-04\n",
            "Epoch 3735/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2884e-04\n",
            "Epoch 3735: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.4988e-04\n",
            "Epoch 3736/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9077e-04\n",
            "Epoch 3736: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4784e-04\n",
            "Epoch 3737/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1532e-04\n",
            "Epoch 3737: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.6573e-04\n",
            "Epoch 3738/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3668e-04\n",
            "Epoch 3738: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4556e-04\n",
            "Epoch 3739/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3739: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.7680e-04\n",
            "Epoch 3740/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1359e-04\n",
            "Epoch 3740: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4995e-04\n",
            "Epoch 3741/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1892e-04\n",
            "Epoch 3741: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.3420e-04\n",
            "Epoch 3742/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3576e-04\n",
            "Epoch 3742: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.6604e-04\n",
            "Epoch 3743/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8157e-04\n",
            "Epoch 3743: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.5910e-04\n",
            "Epoch 3744/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8984e-04\n",
            "Epoch 3744: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5190e-04\n",
            "Epoch 3745/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4440e-04\n",
            "Epoch 3745: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2866e-04\n",
            "Epoch 3746/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1420e-04\n",
            "Epoch 3746: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5683e-04\n",
            "Epoch 3747/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.9018e-04\n",
            "Epoch 3747: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6198e-04\n",
            "Epoch 3748/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3748: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0012\n",
            "Epoch 3749/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8513e-04\n",
            "Epoch 3749: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.2499e-04\n",
            "Epoch 3750/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3750: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3751/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.7637e-04\n",
            "Epoch 3751: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0014\n",
            "Epoch 3752/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4351e-04\n",
            "Epoch 3752: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8231e-04\n",
            "Epoch 3753/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3753: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 3754/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3754: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 3755/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3755: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 3756/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 3756: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0033\n",
            "Epoch 3757/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3757: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3758/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3758: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0013\n",
            "Epoch 3759/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3759: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0015\n",
            "Epoch 3760/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5284e-04\n",
            "Epoch 3760: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0011\n",
            "Epoch 3761/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3761: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3762/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.7339e-04\n",
            "Epoch 3762: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5672e-04\n",
            "Epoch 3763/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3763: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0011\n",
            "Epoch 3764/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3764: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.7388e-04\n",
            "Epoch 3765/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3765: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0010\n",
            "Epoch 3766/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4560e-04\n",
            "Epoch 3766: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3796e-04\n",
            "Epoch 3767/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6787e-04\n",
            "Epoch 3767: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4674e-04\n",
            "Epoch 3768/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.9816e-04\n",
            "Epoch 3768: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3727e-04\n",
            "Epoch 3769/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8577e-04\n",
            "Epoch 3769: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.8355e-04\n",
            "Epoch 3770/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4306e-04\n",
            "Epoch 3770: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.6543e-04\n",
            "Epoch 3771/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3974e-04\n",
            "Epoch 3771: loss did not improve from 0.00043\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.6082e-04\n",
            "Epoch 3772/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2174e-04\n",
            "Epoch 3772: loss improved from 0.00043 to 0.00036, saving model to weights\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.6389e-04\n",
            "Epoch 3773/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7000e-04\n",
            "Epoch 3773: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.9125e-04\n",
            "Epoch 3774/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6680e-04\n",
            "Epoch 3774: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.5543e-04\n",
            "Epoch 3775/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6735e-04\n",
            "Epoch 3775: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.2123e-04\n",
            "Epoch 3776/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7843e-04\n",
            "Epoch 3776: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.9858e-04\n",
            "Epoch 3777/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8589e-04\n",
            "Epoch 3777: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.4046e-04\n",
            "Epoch 3778/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6416e-04\n",
            "Epoch 3778: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.8927e-04\n",
            "Epoch 3779/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9463e-04\n",
            "Epoch 3779: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.7022e-04\n",
            "Epoch 3780/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3780: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0010\n",
            "Epoch 3781/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5260e-04\n",
            "Epoch 3781: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.8676e-04\n",
            "Epoch 3782/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3782: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 3783/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3783: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 3784/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.5379e-04\n",
            "Epoch 3784: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1459e-04\n",
            "Epoch 3785/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3785: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 3786/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.3288e-04\n",
            "Epoch 3786: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 3787/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3787: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 3788/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3788: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0015\n",
            "Epoch 3789/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3789: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 3790/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3790: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 3791/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3791: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 3792/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3792: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 3793/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3793: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3794/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2561e-04\n",
            "Epoch 3794: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3084e-04\n",
            "Epoch 3795/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3795: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 3796/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3796: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9818e-04\n",
            "Epoch 3838/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.5543e-04\n",
            "Epoch 3838: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2340e-04\n",
            "Epoch 3839/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1164e-04\n",
            "Epoch 3839: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.6446e-04\n",
            "Epoch 3840/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1065e-04\n",
            "Epoch 3840: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.9981e-04\n",
            "Epoch 3841/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3548e-04\n",
            "Epoch 3841: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9605e-04\n",
            "Epoch 3842/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9344e-04\n",
            "Epoch 3842: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8924e-04\n",
            "Epoch 3843/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2488e-04\n",
            "Epoch 3843: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.0393e-04\n",
            "Epoch 3844/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0951e-04\n",
            "Epoch 3844: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.5688e-04\n",
            "Epoch 3845/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7477e-04\n",
            "Epoch 3845: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2078e-04\n",
            "Epoch 3846/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2793e-04\n",
            "Epoch 3846: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.6655e-04\n",
            "Epoch 3847/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2834e-04\n",
            "Epoch 3847: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 5.6432e-04\n",
            "Epoch 3848/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9298e-04\n",
            "Epoch 3848: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.4701e-04\n",
            "Epoch 3849/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9243e-04\n",
            "Epoch 3849: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2889e-04\n",
            "Epoch 3850/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3050e-04\n",
            "Epoch 3850: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0315e-04\n",
            "Epoch 3851/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3790e-04\n",
            "Epoch 3851: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3526e-04\n",
            "Epoch 3852/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7917e-04\n",
            "Epoch 3852: loss improved from 0.00036 to 0.00036, saving model to weights\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.5507e-04\n",
            "Epoch 3853/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1944e-04\n",
            "Epoch 3853: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5884e-04\n",
            "Epoch 3854/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0625e-04\n",
            "Epoch 3854: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.1169e-04\n",
            "Epoch 3855/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5728e-04\n",
            "Epoch 3855: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7379e-04\n",
            "Epoch 3856/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4984e-04\n",
            "Epoch 3856: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.0680e-04\n",
            "Epoch 3857/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4269e-04\n",
            "Epoch 3857: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.6775e-04\n",
            "Epoch 3858/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1455e-04\n",
            "Epoch 3858: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.6931e-04\n",
            "Epoch 3859/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1909e-04\n",
            "Epoch 3859: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8691e-04\n",
            "Epoch 3860/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7253e-04\n",
            "Epoch 3860: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.0569e-04\n",
            "Epoch 3861/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.3246e-04\n",
            "Epoch 3861: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2927e-04\n",
            "Epoch 3862/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9730e-04\n",
            "Epoch 3862: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.5165e-04\n",
            "Epoch 3863/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9397e-04\n",
            "Epoch 3863: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7577e-04\n",
            "Epoch 3864/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1222e-04\n",
            "Epoch 3864: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.2277e-04\n",
            "Epoch 3865/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5565e-04\n",
            "Epoch 3865: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.6872e-04\n",
            "Epoch 3866/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5325e-04\n",
            "Epoch 3866: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.1532e-04\n",
            "Epoch 3867/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3867: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.1648e-04\n",
            "Epoch 3868/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1376e-04\n",
            "Epoch 3868: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5649e-04\n",
            "Epoch 3869/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.6146e-04\n",
            "Epoch 3869: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.0697e-04\n",
            "Epoch 3870/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3870: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3871/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3871: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 3872/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4878e-04\n",
            "Epoch 3872: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1312e-04\n",
            "Epoch 3873/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 3873: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 3874/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6723e-04\n",
            "Epoch 3874: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9632e-04\n",
            "Epoch 3875/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3875: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3711e-04\n",
            "Epoch 3876/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3876: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 3877/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4975e-04\n",
            "Epoch 3877: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8894e-04\n",
            "Epoch 3878/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3878: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 3879/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3879: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 3880/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3880: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3881/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3881: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 3882/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2881e-04\n",
            "Epoch 3882: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2218e-04\n",
            "Epoch 3883/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1234e-04\n",
            "Epoch 3883: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3493e-04\n",
            "Epoch 3884/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3884: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 3885/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6710e-04\n",
            "Epoch 3885: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 3886/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3886: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 3887/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 3887: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 3888/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1314e-04\n",
            "Epoch 3888: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0011\n",
            "Epoch 3889/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 3889: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3890/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3890: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3891/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3891: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 3892/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3892: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 3893/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3893: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 3894/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4702e-04\n",
            "Epoch 3894: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5571e-04\n",
            "Epoch 3895/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3895: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3896/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3693e-04\n",
            "Epoch 3896: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 3897/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.6548e-04\n",
            "Epoch 3897: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2030e-04\n",
            "Epoch 3898/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 3898: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 3899/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4428e-04\n",
            "Epoch 3899: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "Epoch 3900/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 3900: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 3901/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0761e-04\n",
            "Epoch 3901: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3902/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3902: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 3903/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8290e-04\n",
            "Epoch 3903: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4841e-04\n",
            "Epoch 3904/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1187e-04\n",
            "Epoch 3904: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9953e-04\n",
            "Epoch 3905/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0037e-04\n",
            "Epoch 3905: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.7225e-04\n",
            "Epoch 3906/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8075e-04\n",
            "Epoch 3906: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.8443e-04\n",
            "Epoch 3907/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.8203e-04\n",
            "Epoch 3907: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3457e-04\n",
            "Epoch 3908/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2428e-04\n",
            "Epoch 3908: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 3909/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3909: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5246e-04\n",
            "Epoch 3910/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.1439e-04\n",
            "Epoch 3910: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0013\n",
            "Epoch 3911/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3911: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1855e-04\n",
            "Epoch 3912/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3912: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0014\n",
            "Epoch 3913/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4316e-04\n",
            "Epoch 3913: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.9587e-04\n",
            "Epoch 3914/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3914: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0012\n",
            "Epoch 3915/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1553e-04\n",
            "Epoch 3915: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 3916/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3916: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.1154e-04\n",
            "Epoch 3917/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3917: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7392e-04\n",
            "Epoch 3918/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0154e-04\n",
            "Epoch 3918: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5758e-04\n",
            "Epoch 3919/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8526e-04\n",
            "Epoch 3919: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.6031e-04\n",
            "Epoch 3920/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3920: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7442e-04\n",
            "Epoch 3921/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3242e-04\n",
            "Epoch 3921: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.8818e-04\n",
            "Epoch 3922/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3922: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3426e-04\n",
            "Epoch 3923/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2675e-04\n",
            "Epoch 3923: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.9445e-04\n",
            "Epoch 3924/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7872e-04\n",
            "Epoch 3924: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.7912e-04\n",
            "Epoch 3925/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9714e-04\n",
            "Epoch 3925: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.8706e-04\n",
            "Epoch 3926/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1174e-04\n",
            "Epoch 3926: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.6082e-04\n",
            "Epoch 3927/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7535e-04\n",
            "Epoch 3927: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6018e-04\n",
            "Epoch 3928/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3458e-04\n",
            "Epoch 3928: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.0475e-04\n",
            "Epoch 3929/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1868e-04\n",
            "Epoch 3929: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2958e-04\n",
            "Epoch 3930/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8542e-04\n",
            "Epoch 3930: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9640e-04\n",
            "Epoch 3931/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6192e-04\n",
            "Epoch 3931: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.3723e-04\n",
            "Epoch 3932/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0418e-04\n",
            "Epoch 3932: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1871e-04\n",
            "Epoch 3933/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6672e-04\n",
            "Epoch 3933: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.9320e-04\n",
            "Epoch 3934/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2241e-04\n",
            "Epoch 3934: loss did not improve from 0.00036\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.5917e-04\n",
            "Epoch 3935/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6273e-04\n",
            "Epoch 3935: loss improved from 0.00036 to 0.00034, saving model to weights\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.4469e-04\n",
            "Epoch 3936/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.6415e-04\n",
            "Epoch 3936: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.1606e-04\n",
            "Epoch 3937/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6049e-04\n",
            "Epoch 3937: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.5165e-04\n",
            "Epoch 3938/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2684e-04\n",
            "Epoch 3938: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.5803e-04\n",
            "Epoch 3939/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2680e-04\n",
            "Epoch 3939: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 4.7001e-04\n",
            "Epoch 3940/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.8407e-04\n",
            "Epoch 3940: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 3941/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0713e-04\n",
            "Epoch 3941: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.4677e-04\n",
            "Epoch 3942/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9143e-04\n",
            "Epoch 3942: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6868e-04\n",
            "Epoch 3943/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4577e-04\n",
            "Epoch 3943: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9278e-04\n",
            "Epoch 3944/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7163e-04\n",
            "Epoch 3944: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.7223e-04\n",
            "Epoch 3945/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7071e-04\n",
            "Epoch 3945: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.4768e-04\n",
            "Epoch 3946/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.4580e-04\n",
            "Epoch 3946: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2571e-04\n",
            "Epoch 3947/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4473e-04\n",
            "Epoch 3947: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.9481e-04\n",
            "Epoch 3948/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3336e-04\n",
            "Epoch 3948: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.5447e-04\n",
            "Epoch 3949/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2210e-04\n",
            "Epoch 3949: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.2604e-04\n",
            "Epoch 3950/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3896e-04\n",
            "Epoch 3950: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.5932e-04\n",
            "Epoch 3951/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5149e-04\n",
            "Epoch 3951: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.2676e-04\n",
            "Epoch 3952/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.5564e-04\n",
            "Epoch 3952: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.3898e-04\n",
            "Epoch 3953/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5217e-04\n",
            "Epoch 3953: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 4.3566e-04\n",
            "Epoch 3954/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6888e-04\n",
            "Epoch 3954: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.5418e-04\n",
            "Epoch 3955/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5730e-04\n",
            "Epoch 3955: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6823e-04\n",
            "Epoch 3956/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8918e-04\n",
            "Epoch 3956: loss did not improve from 0.00034\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 4.9203e-04\n",
            "Epoch 3957/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4231e-04\n",
            "Epoch 3957: loss improved from 0.00034 to 0.00033, saving model to weights\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.3409e-04\n",
            "Epoch 3958/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5468e-04\n",
            "Epoch 3958: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.6182e-04\n",
            "Epoch 3959/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1688e-04\n",
            "Epoch 3959: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.9812e-04\n",
            "Epoch 3960/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4506e-04\n",
            "Epoch 3960: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.6191e-04\n",
            "Epoch 3961/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3961: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2338e-04\n",
            "Epoch 3962/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9877e-04\n",
            "Epoch 3962: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1738e-04\n",
            "Epoch 3963/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.8662e-04\n",
            "Epoch 3963: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2076e-04\n",
            "Epoch 3964/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3964: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 3965/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1974e-04\n",
            "Epoch 3965: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0453e-04\n",
            "Epoch 3966/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3966: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 3967/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3967: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0012\n",
            "Epoch 3968/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3968: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0023\n",
            "Epoch 3969/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3969: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 3970/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 3970: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0014\n",
            "Epoch 3971/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3971: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 3972/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3972: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 3973/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 3973: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0018\n",
            "Epoch 3974/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3974: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0019\n",
            "Epoch 3975/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 3975: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 3976/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 3976: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 3977/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3977: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0010\n",
            "Epoch 3978/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0015e-04\n",
            "Epoch 3978: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.6707e-04\n",
            "Epoch 3979/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8117e-04\n",
            "Epoch 3979: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3649e-04\n",
            "Epoch 3980/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 3980: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 3981/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2701e-04\n",
            "Epoch 3981: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4833e-04\n",
            "Epoch 3982/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7154e-04\n",
            "Epoch 3982: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 3983/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0400e-04\n",
            "Epoch 3983: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.7271e-04\n",
            "Epoch 3984/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1451e-04\n",
            "Epoch 3984: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9531e-04\n",
            "Epoch 3985/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2329e-04\n",
            "Epoch 3985: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5497e-04\n",
            "Epoch 3986/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.3510e-04\n",
            "Epoch 3986: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.8707e-04\n",
            "Epoch 3987/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3987: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.9411e-04\n",
            "Epoch 3988/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1720e-04\n",
            "Epoch 3988: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3471e-04\n",
            "Epoch 3989/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.3675e-04\n",
            "Epoch 3989: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.6158e-04\n",
            "Epoch 3990/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0261e-04\n",
            "Epoch 3990: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6565e-04\n",
            "Epoch 3991/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8266e-04\n",
            "Epoch 3991: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0132e-04\n",
            "Epoch 3992/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4748e-04\n",
            "Epoch 3992: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2697e-04\n",
            "Epoch 3993/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8356e-04\n",
            "Epoch 3993: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5164e-04\n",
            "Epoch 3994/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 3994: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2893e-04\n",
            "Epoch 3995/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8537e-04\n",
            "Epoch 3995: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8699e-04\n",
            "Epoch 3996/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4326e-04\n",
            "Epoch 3996: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0706e-04\n",
            "Epoch 3997/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5942e-04\n",
            "Epoch 3997: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8731e-04\n",
            "Epoch 3998/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4796e-04\n",
            "Epoch 3998: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 3999/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8910e-04\n",
            "Epoch 3999: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9194e-04\n",
            "Epoch 4000/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9708e-04\n",
            "Epoch 4000: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0010\n",
            "Epoch 4001/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7863e-04\n",
            "Epoch 4001: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9642e-04\n",
            "Epoch 4002/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4002: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 4003/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7268e-04\n",
            "Epoch 4003: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9189e-04\n",
            "Epoch 4004/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4004: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 4005/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.6045e-04\n",
            "Epoch 4005: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7935e-04\n",
            "Epoch 4006/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2657e-04\n",
            "Epoch 4006: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.0914e-04\n",
            "Epoch 4007/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9245e-04\n",
            "Epoch 4007: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.2538e-04\n",
            "Epoch 4008/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4008: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 4009/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3611e-04\n",
            "Epoch 4009: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0690e-04\n",
            "Epoch 4010/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4010: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0019\n",
            "Epoch 4011/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3270e-04\n",
            "Epoch 4011: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.5319e-04\n",
            "Epoch 4012/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 4012: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 4013/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.4150e-04\n",
            "Epoch 4013: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.1714e-04\n",
            "Epoch 4014/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 4014: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0034\n",
            "Epoch 4015/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4015: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 4016/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 4016: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0026\n",
            "Epoch 4017/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1053e-04\n",
            "Epoch 4017: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0016\n",
            "Epoch 4018/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 4018: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0026\n",
            "Epoch 4019/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4019: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 4020/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 4020: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 4021/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 4021: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0040\n",
            "Epoch 4022/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4022: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 4023/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0048\n",
            "Epoch 4023: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0052\n",
            "Epoch 4024/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 4024: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 4025/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 4025: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 4026/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8082e-04\n",
            "Epoch 4026: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.7478e-04\n",
            "Epoch 4027/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4027: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 4028/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2414e-04\n",
            "Epoch 4028: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 4029/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 4029: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 4030/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0145e-04\n",
            "Epoch 4030: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.9100e-04\n",
            "Epoch 4031/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4031: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 4032/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6823e-04\n",
            "Epoch 4032: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0013\n",
            "Epoch 4033/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4033: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0011\n",
            "Epoch 4034/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4034: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 4035/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4035: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 4036/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.5739e-04\n",
            "Epoch 4036: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1640e-04\n",
            "Epoch 4037/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5638e-04\n",
            "Epoch 4037: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 4038/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6718e-04\n",
            "Epoch 4038: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.8683e-04\n",
            "Epoch 4039/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0350e-04\n",
            "Epoch 4039: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4850e-04\n",
            "Epoch 4040/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2304e-04\n",
            "Epoch 4040: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.7466e-04\n",
            "Epoch 4041/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1200e-04\n",
            "Epoch 4041: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.4512e-04\n",
            "Epoch 4042/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5310e-04\n",
            "Epoch 4042: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.5459e-04\n",
            "Epoch 4043/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6785e-04\n",
            "Epoch 4043: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0684e-04\n",
            "Epoch 4044/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8683e-04\n",
            "Epoch 4044: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.9264e-04\n",
            "Epoch 4045/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8995e-04\n",
            "Epoch 4045: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.2473e-04\n",
            "Epoch 4046/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8834e-04\n",
            "Epoch 4046: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.9536e-04\n",
            "Epoch 4047/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5030e-04\n",
            "Epoch 4047: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 4.3163e-04\n",
            "Epoch 4048/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4771e-04\n",
            "Epoch 4048: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.9003e-04\n",
            "Epoch 4049/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5768e-04\n",
            "Epoch 4049: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.6198e-04\n",
            "Epoch 4050/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.6693e-04\n",
            "Epoch 4050: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 4051/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1974e-04\n",
            "Epoch 4051: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.1086e-04\n",
            "Epoch 4052/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.9978e-04\n",
            "Epoch 4052: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6121e-04\n",
            "Epoch 4053/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3435e-04\n",
            "Epoch 4053: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.4919e-04\n",
            "Epoch 4054/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4072e-04\n",
            "Epoch 4054: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.1103e-04\n",
            "Epoch 4055/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2488e-04\n",
            "Epoch 4055: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7080e-04\n",
            "Epoch 4056/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3580e-04\n",
            "Epoch 4056: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.9993e-04\n",
            "Epoch 4057/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.0137e-04\n",
            "Epoch 4057: loss improved from 0.00033 to 0.00033, saving model to weights\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.2744e-04\n",
            "Epoch 4058/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4373e-04\n",
            "Epoch 4058: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.3416e-04\n",
            "Epoch 4059/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7887e-04\n",
            "Epoch 4059: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.3788e-04\n",
            "Epoch 4060/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0444e-04\n",
            "Epoch 4060: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4971e-04\n",
            "Epoch 4061/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2483e-04\n",
            "Epoch 4061: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.5079e-04\n",
            "Epoch 4062/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5898e-04\n",
            "Epoch 4062: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0065e-04\n",
            "Epoch 4063/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0685e-04\n",
            "Epoch 4063: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1606e-04\n",
            "Epoch 4064/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8357e-04\n",
            "Epoch 4064: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5735e-04\n",
            "Epoch 4065/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3771e-04\n",
            "Epoch 4065: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1291e-04\n",
            "Epoch 4066/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5422e-04\n",
            "Epoch 4066: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.1020e-04\n",
            "Epoch 4067/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1768e-04\n",
            "Epoch 4067: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.2019e-04\n",
            "Epoch 4068/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8240e-04\n",
            "Epoch 4068: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.4494e-04\n",
            "Epoch 4069/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8766e-04\n",
            "Epoch 4069: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.9856e-04\n",
            "Epoch 4070/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2332e-04\n",
            "Epoch 4070: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1060e-04\n",
            "Epoch 4071/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3570e-04\n",
            "Epoch 4071: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2835e-04\n",
            "Epoch 4072/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6531e-04\n",
            "Epoch 4072: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.0477e-04\n",
            "Epoch 4073/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4073: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 4074/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.7696e-04\n",
            "Epoch 4074: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4860e-04\n",
            "Epoch 4075/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4075: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0015\n",
            "Epoch 4076/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0446e-04\n",
            "Epoch 4076: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.6654e-04\n",
            "Epoch 4077/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 4077: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 4078/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.9474e-04\n",
            "Epoch 4078: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0014\n",
            "Epoch 4079/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 4079: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 4080/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4080: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 4081/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4081: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 4082/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 4082: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "Epoch 4083/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4083: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 4084/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 4084: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "Epoch 4085/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1185e-04\n",
            "Epoch 4085: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 4086/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038\n",
            "Epoch 4086: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0034\n",
            "Epoch 4087/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4087: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0027\n",
            "Epoch 4088/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 4088: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 4089/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 4089: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0032\n",
            "Epoch 4090/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4090: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 4091/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 4091: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 4092/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4092: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0026\n",
            "Epoch 4093/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4093: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.4198e-04\n",
            "Epoch 4094/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4094: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0015\n",
            "Epoch 4095/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4095: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0018\n",
            "Epoch 4096/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4096: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 4097/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 4097: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 4098/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8409e-04\n",
            "Epoch 4098: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 4099/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 4099: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 4100/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4100: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 4101/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4101: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 4102/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 4102: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 4103/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4103: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 4104/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4104: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 9.4176e-04\n",
            "Epoch 4105/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 4105: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 4106/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4106: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4107/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4107: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4108/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2534e-04\n",
            "Epoch 4108: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 4109/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4109: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0010\n",
            "Epoch 4110/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4110: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 4111/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4111: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0015\n",
            "Epoch 4112/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4112: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 4113/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1204e-04\n",
            "Epoch 4113: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9581e-04\n",
            "Epoch 4114/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4114: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 4115/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4115: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0014\n",
            "Epoch 4116/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 4116: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0023\n",
            "Epoch 4117/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4117: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 4118/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 4118: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0033\n",
            "Epoch 4119/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 4119: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 4120/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034\n",
            "Epoch 4120: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 4121/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0047\n",
            "Epoch 4121: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0032\n",
            "Epoch 4122/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4122: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 4123/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4123: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 4124/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 4124: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 4125/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 4125: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 4126/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4126: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 4127/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4127: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4128/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4128: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 4129/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 4129: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 4130/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4130: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 4131/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4131: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0015\n",
            "Epoch 4132/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 4132: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 4133/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.6036e-04\n",
            "Epoch 4133: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 4134/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8027e-04\n",
            "Epoch 4134: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0559e-04\n",
            "Epoch 4135/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4135: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4878e-04\n",
            "Epoch 4136/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8281e-04\n",
            "Epoch 4136: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1591e-04\n",
            "Epoch 4137/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4884e-04\n",
            "Epoch 4137: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.9631e-04\n",
            "Epoch 4138/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6427e-04\n",
            "Epoch 4138: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.0268e-04\n",
            "Epoch 4139/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1064e-04\n",
            "Epoch 4139: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.1834e-04\n",
            "Epoch 4140/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7871e-04\n",
            "Epoch 4140: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.2891e-04\n",
            "Epoch 4141/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1998e-04\n",
            "Epoch 4141: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.0464e-04\n",
            "Epoch 4142/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3529e-04\n",
            "Epoch 4142: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.9861e-04\n",
            "Epoch 4143/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8786e-04\n",
            "Epoch 4143: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0666e-04\n",
            "Epoch 4144/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0469e-04\n",
            "Epoch 4144: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0504e-04\n",
            "Epoch 4145/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3669e-04\n",
            "Epoch 4145: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.4303e-04\n",
            "Epoch 4146/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4574e-04\n",
            "Epoch 4146: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4842e-04\n",
            "Epoch 4147/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0634e-04\n",
            "Epoch 4147: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3521e-04\n",
            "Epoch 4148/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7110e-04\n",
            "Epoch 4148: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5694e-04\n",
            "Epoch 4149/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7633e-04\n",
            "Epoch 4149: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7874e-04\n",
            "Epoch 4150/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3542e-04\n",
            "Epoch 4150: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7018e-04\n",
            "Epoch 4151/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9316e-04\n",
            "Epoch 4151: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.9091e-04\n",
            "Epoch 4152/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0791e-04\n",
            "Epoch 4152: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3329e-04\n",
            "Epoch 4153/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5966e-04\n",
            "Epoch 4153: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9805e-04\n",
            "Epoch 4154/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9956e-04\n",
            "Epoch 4154: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6590e-04\n",
            "Epoch 4155/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6924e-04\n",
            "Epoch 4155: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1870e-04\n",
            "Epoch 4156/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0414e-04\n",
            "Epoch 4156: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.2592e-04\n",
            "Epoch 4157/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2664e-04\n",
            "Epoch 4157: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.5314e-04\n",
            "Epoch 4158/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2019e-04\n",
            "Epoch 4158: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.5888e-04\n",
            "Epoch 4159/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3636e-04\n",
            "Epoch 4159: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.8728e-04\n",
            "Epoch 4160/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.0114e-04\n",
            "Epoch 4160: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.2907e-04\n",
            "Epoch 4161/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7753e-04\n",
            "Epoch 4161: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.3013e-04\n",
            "Epoch 4162/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3342e-04\n",
            "Epoch 4162: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.6178e-04\n",
            "Epoch 4163/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1784e-04\n",
            "Epoch 4163: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.1194e-04\n",
            "Epoch 4164/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6242e-04\n",
            "Epoch 4164: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.1542e-04\n",
            "Epoch 4165/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4434e-04\n",
            "Epoch 4165: loss did not improve from 0.00033\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6163e-04\n",
            "Epoch 4166/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3501e-04\n",
            "Epoch 4166: loss improved from 0.00033 to 0.00029, saving model to weights\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.9125e-04\n",
            "Epoch 4167/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4985e-04\n",
            "Epoch 4167: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.1008e-04\n",
            "Epoch 4168/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7247e-04\n",
            "Epoch 4168: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6527e-04\n",
            "Epoch 4169/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4969e-04\n",
            "Epoch 4169: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6972e-04\n",
            "Epoch 4170/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7157e-04\n",
            "Epoch 4170: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.7653e-04\n",
            "Epoch 4171/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4875e-04\n",
            "Epoch 4171: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5259e-04\n",
            "Epoch 4172/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2876e-04\n",
            "Epoch 4172: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0521e-04\n",
            "Epoch 4173/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5909e-04\n",
            "Epoch 4173: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1962e-04\n",
            "Epoch 4174/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6768e-04\n",
            "Epoch 4174: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.8866e-04\n",
            "Epoch 4175/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4067e-04\n",
            "Epoch 4175: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.9208e-04\n",
            "Epoch 4176/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4176: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4977e-04\n",
            "Epoch 4177/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1553e-04\n",
            "Epoch 4177: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.9691e-04\n",
            "Epoch 4178/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4178: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.0224e-04\n",
            "Epoch 4179/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2595e-04\n",
            "Epoch 4179: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0011\n",
            "Epoch 4180/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4180: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0010\n",
            "Epoch 4181/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4181: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 4182/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4182: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0271e-04\n",
            "Epoch 4183/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9565e-04\n",
            "Epoch 4183: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.9165e-04\n",
            "Epoch 4184/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4988e-04\n",
            "Epoch 4184: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0154e-04\n",
            "Epoch 4185/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.0119e-04\n",
            "Epoch 4185: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7253e-04\n",
            "Epoch 4186/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.6756e-04\n",
            "Epoch 4186: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.5670e-04\n",
            "Epoch 4187/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1612e-04\n",
            "Epoch 4187: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.5653e-04\n",
            "Epoch 4188/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5266e-04\n",
            "Epoch 4188: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.6766e-04\n",
            "Epoch 4189/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1718e-04\n",
            "Epoch 4189: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1602e-04\n",
            "Epoch 4190/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4190: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.9163e-04\n",
            "Epoch 4191/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2029e-04\n",
            "Epoch 4191: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1984e-04\n",
            "Epoch 4192/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2553e-04\n",
            "Epoch 4192: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9555e-04\n",
            "Epoch 4193/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4193: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0017\n",
            "Epoch 4194/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4194: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.5803e-04\n",
            "Epoch 4195/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023\n",
            "Epoch 4195: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 4196/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4196: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0012\n",
            "Epoch 4197/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3326e-04\n",
            "Epoch 4197: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.0630e-04\n",
            "Epoch 4198/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.3096e-04\n",
            "Epoch 4198: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0271e-04\n",
            "Epoch 4199/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.6219e-04\n",
            "Epoch 4199: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 4200/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2921e-04\n",
            "Epoch 4200: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.4543e-04\n",
            "Epoch 4201/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9234e-04\n",
            "Epoch 4201: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7277e-04\n",
            "Epoch 4202/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6403e-04\n",
            "Epoch 4202: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 4.7358e-04\n",
            "Epoch 4203/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6662e-04\n",
            "Epoch 4203: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.5950e-04\n",
            "Epoch 4204/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4204: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.5554e-04\n",
            "Epoch 4205/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6312e-04\n",
            "Epoch 4205: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.4370e-04\n",
            "Epoch 4206/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4206: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 4207/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4207: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 4208/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 4208: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0020\n",
            "Epoch 4209/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4209: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9988e-04\n",
            "Epoch 4210/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4210: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0010\n",
            "Epoch 4211/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4211: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 4212/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4212: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0017\n",
            "Epoch 4213/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.5511e-04\n",
            "Epoch 4213: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9545e-04\n",
            "Epoch 4214/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4214: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0021\n",
            "Epoch 4215/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4311e-04\n",
            "Epoch 4215: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3078e-04\n",
            "Epoch 4216/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4216: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 4217/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4217: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5435e-04\n",
            "Epoch 4218/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4218: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 4219/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4219: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6777e-04\n",
            "Epoch 4220/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.8243e-04\n",
            "Epoch 4220: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 4221/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.9240e-04\n",
            "Epoch 4221: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.1744e-04\n",
            "Epoch 4222/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4222: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 4223/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4223: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 4224/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9693e-04\n",
            "Epoch 4224: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.1224e-04\n",
            "Epoch 4225/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4225: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0017\n",
            "Epoch 4226/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.1096e-04\n",
            "Epoch 4226: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9404e-04\n",
            "Epoch 4227/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4227: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8124e-04\n",
            "Epoch 4228/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0364e-04\n",
            "Epoch 4228: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.2704e-04\n",
            "Epoch 4229/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4229: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0015\n",
            "Epoch 4230/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4230: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 4231/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4231: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0019\n",
            "Epoch 4232/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4232: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4233/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 4233: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0023\n",
            "Epoch 4234/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4234: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.4349e-04\n",
            "Epoch 4235/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4235: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0015\n",
            "Epoch 4236/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.3359e-04\n",
            "Epoch 4236: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5827e-04\n",
            "Epoch 4237/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4237: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.8128e-04\n",
            "Epoch 4238/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8035e-04\n",
            "Epoch 4238: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0011\n",
            "Epoch 4239/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4239: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 4240/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8612e-04\n",
            "Epoch 4240: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 4241/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4241: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.7821e-04\n",
            "Epoch 4242/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8532e-04\n",
            "Epoch 4242: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7021e-04\n",
            "Epoch 4243/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7251e-04\n",
            "Epoch 4243: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 4.3984e-04\n",
            "Epoch 4244/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2937e-04\n",
            "Epoch 4244: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 4245/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.1503e-04\n",
            "Epoch 4245: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.9949e-04\n",
            "Epoch 4246/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8930e-04\n",
            "Epoch 4246: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.0069e-04\n",
            "Epoch 4247/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4247: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.5411e-04\n",
            "Epoch 4248/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2811e-04\n",
            "Epoch 4248: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0422e-04\n",
            "Epoch 4249/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4249: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 4250/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4197e-04\n",
            "Epoch 4250: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1116e-04\n",
            "Epoch 4251/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019\n",
            "Epoch 4251: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 4252/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4252: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 4253/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.8663e-04\n",
            "Epoch 4253: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0018\n",
            "Epoch 4254/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 4254: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0027\n",
            "Epoch 4255/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4255: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0012\n",
            "Epoch 4256/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 4256: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 4257/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4257: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5648e-04\n",
            "Epoch 4258/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4258: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 4259/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4259: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 4260/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 4260: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 4261/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4261: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 4262/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 4262: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 4263/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6280e-04\n",
            "Epoch 4263: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 4264/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4264: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 4265/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.8959e-04\n",
            "Epoch 4265: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.1907e-04\n",
            "Epoch 4266/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.5326e-04\n",
            "Epoch 4266: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0010\n",
            "Epoch 4267/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2364e-04\n",
            "Epoch 4267: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.2998e-04\n",
            "Epoch 4268/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5677e-04\n",
            "Epoch 4268: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7533e-04\n",
            "Epoch 4269/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0712e-04\n",
            "Epoch 4269: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.7733e-04\n",
            "Epoch 4270/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3428e-04\n",
            "Epoch 4270: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.3354e-04\n",
            "Epoch 4271/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6968e-04\n",
            "Epoch 4271: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.2378e-04\n",
            "Epoch 4272/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8371e-04\n",
            "Epoch 4272: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.6963e-04\n",
            "Epoch 4273/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7288e-04\n",
            "Epoch 4273: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.7384e-04\n",
            "Epoch 4274/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.6103e-04\n",
            "Epoch 4274: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.1121e-04\n",
            "Epoch 4275/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7922e-04\n",
            "Epoch 4275: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.5258e-04\n",
            "Epoch 4276/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8520e-04\n",
            "Epoch 4276: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.9714e-04\n",
            "Epoch 4277/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5261e-04\n",
            "Epoch 4277: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.8197e-04\n",
            "Epoch 4278/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4513e-04\n",
            "Epoch 4278: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.2477e-04\n",
            "Epoch 4279/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.2177e-04\n",
            "Epoch 4279: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6187e-04\n",
            "Epoch 4280/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9446e-04\n",
            "Epoch 4280: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.9621e-04\n",
            "Epoch 4281/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9685e-04\n",
            "Epoch 4281: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.6300e-04\n",
            "Epoch 4282/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9346e-04\n",
            "Epoch 4282: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1060e-04\n",
            "Epoch 4283/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5233e-04\n",
            "Epoch 4283: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.6249e-04\n",
            "Epoch 4284/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0078e-04\n",
            "Epoch 4284: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2701e-04\n",
            "Epoch 4285/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1999e-04\n",
            "Epoch 4285: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.8208e-04\n",
            "Epoch 4286/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7228e-04\n",
            "Epoch 4286: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.8098e-04\n",
            "Epoch 4287/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4287: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 4288/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2022e-04\n",
            "Epoch 4288: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0010\n",
            "Epoch 4289/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 4289: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 4290/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7223e-04\n",
            "Epoch 4290: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 4291/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 4291: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 4292/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3233e-04\n",
            "Epoch 4292: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 4293/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0053\n",
            "Epoch 4293: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0050\n",
            "Epoch 4294/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4294: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 4295/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 4295: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0023\n",
            "Epoch 4296/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9138e-04\n",
            "Epoch 4296: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 4297/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 4297: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 4298/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5130e-04\n",
            "Epoch 4298: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 4299/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 4299: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 4300/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2354e-04\n",
            "Epoch 4300: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 4301/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4301: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 4302/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.1350e-04\n",
            "Epoch 4302: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 4303/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 4303: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0016\n",
            "Epoch 4304/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4304: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 4305/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4305: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0011\n",
            "Epoch 4306/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 4306: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0030\n",
            "Epoch 4307/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4307: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 4308/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 4308: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 4309/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 4309: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 4310/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 4310: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "Epoch 4311/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 4311: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0018\n",
            "Epoch 4312/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4312: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 4313/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 4313: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0021\n",
            "Epoch 4314/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4314: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 4315/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4315: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 4316/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4316: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0018\n",
            "Epoch 4317/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7927e-04\n",
            "Epoch 4317: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1162e-04\n",
            "Epoch 4318/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4318: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 4319/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7137e-04\n",
            "Epoch 4319: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0240e-04\n",
            "Epoch 4320/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4320: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0015\n",
            "Epoch 4321/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2114e-04\n",
            "Epoch 4321: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.8919e-04\n",
            "Epoch 4322/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 4322: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 4323/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.7598e-04\n",
            "Epoch 4323: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9721e-04\n",
            "Epoch 4324/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 4324: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 4325/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8215e-04\n",
            "Epoch 4325: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.3593e-04\n",
            "Epoch 4326/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4326: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3953e-04\n",
            "Epoch 4327/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8075e-04\n",
            "Epoch 4327: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.7406e-04\n",
            "Epoch 4328/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4328: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5305e-04\n",
            "Epoch 4329/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0522e-04\n",
            "Epoch 4329: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 4330/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4330: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.9328e-04\n",
            "Epoch 4331/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3522e-04\n",
            "Epoch 4331: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.4856e-04\n",
            "Epoch 4332/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6444e-04\n",
            "Epoch 4332: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.3788e-04\n",
            "Epoch 4333/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4374e-04\n",
            "Epoch 4333: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.3503e-04\n",
            "Epoch 4334/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.4627e-04\n",
            "Epoch 4334: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.4992e-04\n",
            "Epoch 4335/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5089e-04\n",
            "Epoch 4335: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6975e-04\n",
            "Epoch 4336/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0034e-04\n",
            "Epoch 4336: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.3596e-04\n",
            "Epoch 4337/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9104e-04\n",
            "Epoch 4337: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.2085e-04\n",
            "Epoch 4338/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2005e-04\n",
            "Epoch 4338: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.1198e-04\n",
            "Epoch 4339/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8256e-04\n",
            "Epoch 4339: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6139e-04\n",
            "Epoch 4340/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4159e-04\n",
            "Epoch 4340: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.0227e-04\n",
            "Epoch 4341/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4341: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2705e-04\n",
            "Epoch 4342/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9772e-04\n",
            "Epoch 4342: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2896e-04\n",
            "Epoch 4343/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0211e-04\n",
            "Epoch 4343: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3683e-04\n",
            "Epoch 4344/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2311e-04\n",
            "Epoch 4344: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 4345/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4195e-04\n",
            "Epoch 4345: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.0310e-04\n",
            "Epoch 4346/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4346: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3814e-04\n",
            "Epoch 4347/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6206e-04\n",
            "Epoch 4347: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.4786e-04\n",
            "Epoch 4348/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0206e-04\n",
            "Epoch 4348: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7889e-04\n",
            "Epoch 4349/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.8116e-04\n",
            "Epoch 4349: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.2209e-04\n",
            "Epoch 4350/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7879e-04\n",
            "Epoch 4350: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7028e-04\n",
            "Epoch 4351/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5918e-04\n",
            "Epoch 4351: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.5855e-04\n",
            "Epoch 4352/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.0058e-04\n",
            "Epoch 4352: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1478e-04\n",
            "Epoch 4353/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8703e-04\n",
            "Epoch 4353: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 4.4251e-04\n",
            "Epoch 4354/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0052e-04\n",
            "Epoch 4354: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.3327e-04\n",
            "Epoch 4355/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9313e-04\n",
            "Epoch 4355: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 4.5199e-04\n",
            "Epoch 4356/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5401e-04\n",
            "Epoch 4356: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.4090e-04\n",
            "Epoch 4357/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1327e-04\n",
            "Epoch 4357: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.9224e-04\n",
            "Epoch 4358/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9311e-04\n",
            "Epoch 4358: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.1474e-04\n",
            "Epoch 4359/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5549e-04\n",
            "Epoch 4359: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.9499e-04\n",
            "Epoch 4360/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3317e-04\n",
            "Epoch 4360: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3896e-04\n",
            "Epoch 4361/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6293e-04\n",
            "Epoch 4361: loss did not improve from 0.00029\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.8937e-04\n",
            "Epoch 4362/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6023e-04\n",
            "Epoch 4362: loss improved from 0.00029 to 0.00025, saving model to weights\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.4851e-04\n",
            "Epoch 4363/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8003e-04\n",
            "Epoch 4363: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.2156e-04\n",
            "Epoch 4364/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2295e-04\n",
            "Epoch 4364: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.3788e-04\n",
            "Epoch 4365/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9076e-04\n",
            "Epoch 4365: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.4702e-04\n",
            "Epoch 4366/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5703e-04\n",
            "Epoch 4366: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.5608e-04\n",
            "Epoch 4367/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4030e-04\n",
            "Epoch 4367: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.3420e-04\n",
            "Epoch 4368/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5534e-04\n",
            "Epoch 4368: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.8519e-04\n",
            "Epoch 4369/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3876e-04\n",
            "Epoch 4369: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.9336e-04\n",
            "Epoch 4370/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4950e-04\n",
            "Epoch 4370: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5259e-04\n",
            "Epoch 4371/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7339e-04\n",
            "Epoch 4371: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.3394e-04\n",
            "Epoch 4372/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5065e-04\n",
            "Epoch 4372: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.4256e-04\n",
            "Epoch 4373/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9261e-04\n",
            "Epoch 4373: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.8413e-04\n",
            "Epoch 4374/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0746e-04\n",
            "Epoch 4374: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.4863e-04\n",
            "Epoch 4375/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4051e-04\n",
            "Epoch 4375: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.8043e-04\n",
            "Epoch 4376/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.0985e-04\n",
            "Epoch 4376: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.8404e-04\n",
            "Epoch 4377/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2710e-04\n",
            "Epoch 4377: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7560e-04\n",
            "Epoch 4378/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6775e-04\n",
            "Epoch 4378: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.7443e-04\n",
            "Epoch 4379/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4006e-04\n",
            "Epoch 4379: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0709e-04\n",
            "Epoch 4380/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4764e-04\n",
            "Epoch 4380: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.2321e-04\n",
            "Epoch 4381/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4236e-04\n",
            "Epoch 4381: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6966e-04\n",
            "Epoch 4382/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8954e-04\n",
            "Epoch 4382: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9102e-04\n",
            "Epoch 4383/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9269e-04\n",
            "Epoch 4383: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0452e-04\n",
            "Epoch 4384/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1792e-04\n",
            "Epoch 4384: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9604e-04\n",
            "Epoch 4385/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9169e-04\n",
            "Epoch 4385: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.8716e-04\n",
            "Epoch 4386/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8142e-04\n",
            "Epoch 4386: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7194e-04\n",
            "Epoch 4387/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0076e-04\n",
            "Epoch 4387: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.1003e-04\n",
            "Epoch 4388/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2550e-04\n",
            "Epoch 4388: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4233e-04\n",
            "Epoch 4389/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.9615e-04\n",
            "Epoch 4389: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7265e-04\n",
            "Epoch 4390/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4141e-04\n",
            "Epoch 4390: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.2225e-04\n",
            "Epoch 4391/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4391: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9687e-04\n",
            "Epoch 4392/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5592e-04\n",
            "Epoch 4392: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.2350e-04\n",
            "Epoch 4393/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5666e-04\n",
            "Epoch 4393: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0011\n",
            "Epoch 4394/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4394: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3718e-04\n",
            "Epoch 4395/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.3248e-04\n",
            "Epoch 4395: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.2971e-04\n",
            "Epoch 4396/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4396: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 4397/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0647e-04\n",
            "Epoch 4397: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7150e-04\n",
            "Epoch 4398/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4398: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0016\n",
            "Epoch 4399/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4399: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9976e-04\n",
            "Epoch 4400/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4400: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 4401/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028\n",
            "Epoch 4401: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 4402/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5372e-04\n",
            "Epoch 4402: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 4403/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029\n",
            "Epoch 4403: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 4404/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9474e-04\n",
            "Epoch 4404: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0011\n",
            "Epoch 4405/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0041\n",
            "Epoch 4405: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "Epoch 4406/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.5869e-04\n",
            "Epoch 4406: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0011\n",
            "Epoch 4407/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024\n",
            "Epoch 4407: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 4408/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9602e-04\n",
            "Epoch 4408: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "Epoch 4409/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4409: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 4410/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4410: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0018\n",
            "Epoch 4411/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 4411: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0021\n",
            "Epoch 4412/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4412: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 4413/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 4413: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0022\n",
            "Epoch 4414/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4414: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 4415/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 4415: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 4416/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4416: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 4417/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035\n",
            "Epoch 4417: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 4418/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025\n",
            "Epoch 4418: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0038\n",
            "Epoch 4419/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0036\n",
            "Epoch 4419: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0031\n",
            "Epoch 4420/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037\n",
            "Epoch 4420: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0038\n",
            "Epoch 4421/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026\n",
            "Epoch 4421: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 4422/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032\n",
            "Epoch 4422: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0040\n",
            "Epoch 4423/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0043\n",
            "Epoch 4423: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0036\n",
            "Epoch 4424/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030\n",
            "Epoch 4424: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0031\n",
            "Epoch 4425/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 4425: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 4426/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
            "Epoch 4426: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0032\n",
            "Epoch 4427/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020\n",
            "Epoch 4427: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 4428/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039\n",
            "Epoch 4428: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0037\n",
            "Epoch 4429/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4429: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
            "Epoch 4430/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0052\n",
            "Epoch 4430: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0047\n",
            "Epoch 4431/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4431: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 4432/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033\n",
            "Epoch 4432: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 4433/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4433: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 4434/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022\n",
            "Epoch 4434: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 4435/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4435: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 4436/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4436: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5319e-04\n",
            "Epoch 4437/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4437: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 4438/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4438: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8980e-04\n",
            "Epoch 4439/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4439: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0014\n",
            "Epoch 4440/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1526e-04\n",
            "Epoch 4440: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 4441/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4441: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 4442/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7362e-04\n",
            "Epoch 4442: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 4443/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4443: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 4444/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1833e-04\n",
            "Epoch 4444: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9428e-04\n",
            "Epoch 4445/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4445: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.9765e-04\n",
            "Epoch 4446/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5395e-04\n",
            "Epoch 4446: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3396e-04\n",
            "Epoch 4447/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.6885e-04\n",
            "Epoch 4447: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4284e-04\n",
            "Epoch 4448/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2986e-04\n",
            "Epoch 4448: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 8.8291e-04\n",
            "Epoch 4449/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.8844e-04\n",
            "Epoch 4449: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3491e-04\n",
            "Epoch 4450/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3636e-04\n",
            "Epoch 4450: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0011\n",
            "Epoch 4451/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4451: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0014\n",
            "Epoch 4452/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4626e-04\n",
            "Epoch 4452: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.0425e-04\n",
            "Epoch 4453/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.2389e-04\n",
            "Epoch 4453: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.4808e-04\n",
            "Epoch 4454/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015\n",
            "Epoch 4454: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0015\n",
            "Epoch 4455/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1601e-04\n",
            "Epoch 4455: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2793e-04\n",
            "Epoch 4456/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4456: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 4457/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4457: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.6412e-04\n",
            "Epoch 4458/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017\n",
            "Epoch 4458: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0015\n",
            "Epoch 4459/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2570e-04\n",
            "Epoch 4459: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3738e-04\n",
            "Epoch 4460/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4460: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 4461/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9886e-04\n",
            "Epoch 4461: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1677e-04\n",
            "Epoch 4462/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4462: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0013\n",
            "Epoch 4463/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4463: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0011\n",
            "Epoch 4464/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7686e-04\n",
            "Epoch 4464: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.6084e-04\n",
            "Epoch 4465/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.8995e-04\n",
            "Epoch 4465: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.7452e-04\n",
            "Epoch 4466/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4466: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 4467/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4272e-04\n",
            "Epoch 4467: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8305e-04\n",
            "Epoch 4468/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2533e-04\n",
            "Epoch 4468: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1015e-04\n",
            "Epoch 4469/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7412e-04\n",
            "Epoch 4469: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7177e-04\n",
            "Epoch 4470/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1158e-04\n",
            "Epoch 4470: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1401e-04\n",
            "Epoch 4471/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.6647e-04\n",
            "Epoch 4471: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2329e-04\n",
            "Epoch 4472/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6102e-04\n",
            "Epoch 4472: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1347e-04\n",
            "Epoch 4473/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2319e-04\n",
            "Epoch 4473: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.5936e-04\n",
            "Epoch 4474/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4385e-04\n",
            "Epoch 4474: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.1110e-04\n",
            "Epoch 4475/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3472e-04\n",
            "Epoch 4475: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.6456e-04\n",
            "Epoch 4476/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5926e-04\n",
            "Epoch 4476: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.8301e-04\n",
            "Epoch 4477/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.8808e-04\n",
            "Epoch 4477: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.5685e-04\n",
            "Epoch 4478/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3464e-04\n",
            "Epoch 4478: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.4380e-04\n",
            "Epoch 4479/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0453e-04\n",
            "Epoch 4479: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9555e-04\n",
            "Epoch 4480/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.4555e-04\n",
            "Epoch 4480: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5813e-04\n",
            "Epoch 4481/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0542e-04\n",
            "Epoch 4481: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.9567e-04\n",
            "Epoch 4482/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4482: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4199e-04\n",
            "Epoch 4483/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7554e-04\n",
            "Epoch 4483: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 4484/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012\n",
            "Epoch 4484: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8145e-04\n",
            "Epoch 4485/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3098e-04\n",
            "Epoch 4485: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4229e-04\n",
            "Epoch 4486/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010\n",
            "Epoch 4486: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3211e-04\n",
            "Epoch 4487/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1324e-04\n",
            "Epoch 4487: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8853e-04\n",
            "Epoch 4488/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0620e-04\n",
            "Epoch 4488: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.2996e-04\n",
            "Epoch 4489/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2463e-04\n",
            "Epoch 4489: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.5960e-04\n",
            "Epoch 4490/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.3021e-04\n",
            "Epoch 4490: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.8604e-04\n",
            "Epoch 4491/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018\n",
            "Epoch 4491: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0022\n",
            "Epoch 4492/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.2194e-04\n",
            "Epoch 4492: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0618e-04\n",
            "Epoch 4493/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021\n",
            "Epoch 4493: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 4494/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9874e-04\n",
            "Epoch 4494: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 4495/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5132e-04\n",
            "Epoch 4495: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9018e-04\n",
            "Epoch 4496/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7908e-04\n",
            "Epoch 4496: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7887e-04\n",
            "Epoch 4497/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6576e-04\n",
            "Epoch 4497: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.6640e-04\n",
            "Epoch 4498/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0367e-04\n",
            "Epoch 4498: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.1712e-04\n",
            "Epoch 4499/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3687e-04\n",
            "Epoch 4499: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.7908e-04\n",
            "Epoch 4500/4500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1592e-04\n",
            "Epoch 4500: loss did not improve from 0.00025\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.2760e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4: Plot the outputs (final states) of this Neural ODE, as well as the analytic solutions, for a new set of inputs given below.**\n",
        "---\n",
        "```x = np.linspace(0,30,1000)```"
      ],
      "metadata": {
        "id": "zKXTk5UYUPvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution (to be removed before GitHub upload)**\n",
        "----"
      ],
      "metadata": {
        "id": "WVFdm5edVjYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(0,30,1000) # inputs\n",
        "y = y(x) # analytic soluton for y(t)\n",
        "y_prime = y_prime(x) # analytic solution for y'(t)"
      ],
      "metadata": {
        "id": "YWZiWdi7Vpf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Next, we load the saved weights of the Neural ODE and make predictions for new inputs."
      ],
      "metadata": {
        "id": "Eg1xdV3EV0Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ODE_model.load_weights(\"weights\")\n",
        "new_y_prime = ODE_model.predict(x) # first axis is y(t), second axis is yprime(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AnkQMTDVz9S",
        "outputId": "acfa98b7-199f-4df3-fa52-f7405c39c065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5d5sz5FyHBM"
      },
      "source": [
        "* Then, we plot the predictions of this Neural ODE against analytic solutions of the harmonic oscillator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "Gk6RNf5yyGdU",
        "outputId": "4b4ae500-1e75-4eb6-cabe-dd680b61cbd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a1808130730>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(6,4))\n",
        "c1 = \"#1F77B4\"\n",
        "c2 = \"#E25140\"\n",
        "plt.subplots_adjust(left=0.12, right=0.95, top=0.95, hspace=0.6)\n",
        "\n",
        "ax = plt.subplot(3, 1, 1)\n",
        "ax.annotate('(a)', xycoords=\"axes fraction\", xy=(-0.13,0.9))\n",
        "plt.xlabel(\"$t$\")\n",
        "plt.ylabel(\"$y(t)$\")\n",
        "plt.plot(x, y, color=c1, label=\"Analytic\")\n",
        "plt.plot(x, new_y_prime[:,0], color=c2, linestyle=\"dotted\", label=\"$y(t)$\")\n",
        "plt.legend(loc='upper right', frameon=False, ncol=2)\n",
        "\n",
        "ax = plt.subplot(3, 1, 2)\n",
        "ax.annotate('(b)', xycoords=\"axes fraction\", xy=(-0.13,0.9))\n",
        "plt.xlabel(\"$t$\")\n",
        "plt.ylabel(\"$y'(t)$\")\n",
        "plt.plot(x, y_prime, color=c1, label=\"Analytic\")\n",
        "plt.plot(x, new_y_prime[:,1], color=c2, linestyle=\"dotted\", label=\"$y''(t)$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "* https://arxiv.org/pdf/1806.07366.pdf\n",
        "* https://lukasschwarz.de/deqnn#eq-oden\n",
        "* https://docs.kidger.site/diffrax/examples/neural_ode/\n",
        "* https://github.com/titu1994/tfdiffeq\n"
      ],
      "metadata": {
        "id": "B7g45zXHww4w"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}